{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "#from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if DEVICE.type == 'cuda':\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_to_MiB(row):\n",
    "\t# verify if has string ' MiB'\n",
    "\tif 'MiB' in str(row):\n",
    "\t\trow = row.replace(' MiB', '')\n",
    "\t\trow = float(row)\n",
    "\telse:\n",
    "\t\trow = float(row) / np.power(2, 20)\n",
    "\treturn row\n",
    "\n",
    "\n",
    "def MHz_to_GHz(row):\n",
    "\t# verify if has string ' GHz'\n",
    "\tif 'GHz' in str(row):\n",
    "\t\trow = row.replace(' GHz', '')\n",
    "\t\t# convert to float\n",
    "\t\trow = float(row)\n",
    "\telse:\n",
    "\t\trow = row.replace(' MHz', '')\n",
    "\t\trow = float(row) / 1000\n",
    "\treturn row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('../results_new/execution_time.csv')\n",
    "results_savio_df = pd.read_csv('../results_savio_new/execution_time.csv')\n",
    "results_df = pd.concat([results_df, results_savio_df], ignore_index=True)\n",
    "# preprocessing\n",
    "results_df['total_cpu_usage'] = results_df['total_cpu_usage'].str.replace('%', '').astype(float) / 100\n",
    "results_df['max_ram_usage'] = results_df['max_ram_usage'] / 1024\n",
    "results_df['l2_cache_size'] = results_df['l2_cache_size'].apply(bits_to_MiB)\n",
    "results_df['l3_cache_size'] = results_df['l3_cache_size'].apply(bits_to_MiB)\n",
    "results_df['ghz_actual_friendly'] = results_df['hz_actual_friendly'].apply(MHz_to_GHz)\n",
    "results_df['ghz_advertised_friendly'] = results_df['hz_advertised_friendly'].str.replace('GHz', '').astype(float)\n",
    "results_df = results_df.drop(columns=['hz_actual_friendly', 'hz_advertised_friendly', 'arch', 'vendor_id_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "      <th>total_cpu_usage</th>\n",
       "      <th>max_ram_usage</th>\n",
       "      <th>brand_raw</th>\n",
       "      <th>count</th>\n",
       "      <th>l2_cache_size</th>\n",
       "      <th>l3_cache_size</th>\n",
       "      <th>l2_cache_line_size</th>\n",
       "      <th>l2_cache_associativity</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>ghz_actual_friendly</th>\n",
       "      <th>ghz_advertised_friendly</th>\n",
       "      <th>total_time_target</th>\n",
       "      <th>brand_raw_target</th>\n",
       "      <th>count_target</th>\n",
       "      <th>l2_cache_size_target</th>\n",
       "      <th>l3_cache_size_target</th>\n",
       "      <th>l2_cache_line_size_target</th>\n",
       "      <th>l2_cache_associativity_target</th>\n",
       "      <th>ghz_advertised_friendly_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1436.714844</td>\n",
       "      <td>Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>KNP</td>\n",
       "      <td>4.1729</td>\n",
       "      <td>2.9</td>\n",
       "      <td>45.91</td>\n",
       "      <td>13th Gen Intel(R) Core(TM) i5-1335U</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>7</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1436.714844</td>\n",
       "      <td>Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>KNP</td>\n",
       "      <td>4.1729</td>\n",
       "      <td>2.9</td>\n",
       "      <td>25.77</td>\n",
       "      <td>13th Gen Intel(R) Core(TM) i5-1335U</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>7</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_time  total_cpu_usage  max_ram_usage  \\\n",
       "5       13.47             0.99    1436.714844   \n",
       "6       13.47             0.99    1436.714844   \n",
       "\n",
       "                                  brand_raw  count  l2_cache_size  \\\n",
       "5  Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz     12            1.5   \n",
       "6  Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz     12            1.5   \n",
       "\n",
       "   l3_cache_size  l2_cache_line_size  l2_cache_associativity benchmark  \\\n",
       "5           12.0                 256                       6       KNP   \n",
       "6           12.0                 256                       6       KNP   \n",
       "\n",
       "   ghz_actual_friendly  ghz_advertised_friendly  total_time_target  \\\n",
       "5               4.1729                      2.9              45.91   \n",
       "6               4.1729                      2.9              25.77   \n",
       "\n",
       "                      brand_raw_target  count_target  l2_cache_size_target  \\\n",
       "5  13th Gen Intel(R) Core(TM) i5-1335U            12                   7.5   \n",
       "6  13th Gen Intel(R) Core(TM) i5-1335U            12                   7.5   \n",
       "\n",
       "   l3_cache_size_target  l2_cache_line_size_target  \\\n",
       "5                  12.0                       1280   \n",
       "6                  12.0                       1280   \n",
       "\n",
       "   l2_cache_associativity_target  ghz_advertised_friendly_target  \n",
       "5                              7                           2.496  \n",
       "6                              7                           2.496  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the target dataset\n",
    "target_df = results_df[['total_time', 'brand_raw', 'count', 'l2_cache_size', 'l3_cache_size', 'l2_cache_line_size', 'l2_cache_associativity', 'ghz_advertised_friendly', 'benchmark']].copy()\n",
    "# Rename columns to *_target\n",
    "target_df = target_df.rename(columns={\n",
    "    'total_time': 'total_time_target',\n",
    "    'brand_raw': 'brand_raw_target',\n",
    "    'count': 'count_target',\n",
    "    'l2_cache_size': 'l2_cache_size_target',\n",
    "    'l3_cache_size': 'l3_cache_size_target',\n",
    "    'l2_cache_line_size': 'l2_cache_line_size_target',\n",
    "    'l2_cache_associativity': 'l2_cache_associativity_target',\n",
    "    'ghz_advertised_friendly': 'ghz_advertised_friendly_target',\n",
    "})\n",
    "\n",
    "dataset_df = pd.merge(results_df, target_df, how='inner', on='benchmark')\n",
    "dataset_df = dataset_df[dataset_df['brand_raw'] != dataset_df['brand_raw_target']]\n",
    "dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove one computer for testing\n",
    "g_train = dataset_df[(dataset_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (dataset_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "g_test = dataset_df[dataset_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df = dataset_df[dataset_df['benchmark'].isin(['MATRIX_MULT', 'MATRIX_MULT2', 'MATRIX_MULT3'])]\n",
    "# remove one computer for testing\n",
    "mm_train = mm_df[(mm_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (mm_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "mm_test = mm_df[mm_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df = dataset_df[~dataset_df['benchmark'].isin(['MATRIX_MULT', 'MATRIX_MULT2', 'MATRIX_MULT3'])]\n",
    "# remove one computer for testing\n",
    "st_train = st_df[(st_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (st_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "st_test = st_df[st_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "# g_test = pd.read_csv('csv/g_test.csv')\n",
    "# st_test = pd.read_csv('csv/st_test.csv')\n",
    "# mm_test = pd.read_csv('csv/mm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'total_time_target'\n",
    "features = mm_test.columns.copy().drop(target).drop(['benchmark','brand_raw', 'brand_raw_target'])\n",
    "features_st = features.copy().drop(['count', 'count_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general data\n",
    "## split data\n",
    "X_g_train = g_train[features]\n",
    "y_g_train = g_train[target]\n",
    "\n",
    "X_g_test = g_test[features]\n",
    "y_g_test = g_test[target]\n",
    "\n",
    "## normalize data\n",
    "x_g_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_g_train = x_g_scaler.fit_transform(X_g_train)\n",
    "X_g_test = x_g_scaler.transform(X_g_test)\n",
    "y_g_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_g_train = y_g_scaler.fit_transform(y_g_train.values.reshape(-1, 1))\n",
    "y_g_test = y_g_scaler.transform(y_g_test.values.reshape(-1, 1))\n",
    "\n",
    "## convert to tensor\n",
    "X_g_train_t = torch.tensor(X_g_train, dtype=torch.float32)\n",
    "X_g_test_t = torch.tensor(X_g_test, dtype=torch.float32)\n",
    "y_g_train_t = torch.tensor(y_g_train, dtype=torch.float32)\n",
    "y_g_test_t = torch.tensor(y_g_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single thread data\n",
    "## split data\n",
    "X_st_train = st_train[features_st]\n",
    "y_st_train = st_train[target]\n",
    "\n",
    "X_st_test = st_test[features_st]\n",
    "y_st_test = st_test[target]\n",
    "\n",
    "## normalize data\n",
    "x_st_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_st_train = x_st_scaler.fit_transform(X_st_train)\n",
    "X_st_test = x_st_scaler.transform(X_st_test)\n",
    "y_st_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_st_train = y_st_scaler.fit_transform(y_st_train.values.reshape(-1, 1))\n",
    "y_st_test = y_st_scaler.transform(y_st_test.values.reshape(-1, 1))\n",
    "\n",
    "## convert to tensor\n",
    "X_st_train_t = torch.tensor(X_st_train, dtype=torch.float32)\n",
    "X_st_test_t = torch.tensor(X_st_test, dtype=torch.float32)\n",
    "y_st_train_t = torch.tensor(y_st_train, dtype=torch.float32)\n",
    "y_st_test_t = torch.tensor(y_st_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi thread data\n",
    "## split data\n",
    "X_mm_train = mm_train[features]\n",
    "y_mm_train = mm_train[target]\n",
    "\n",
    "X_mm_test = mm_test[features]\n",
    "y_mm_test = mm_test[target]\n",
    "\n",
    "## normalize data\n",
    "x_mm_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_mm_train = x_mm_scaler.fit_transform(X_mm_train)\n",
    "X_mm_test = x_mm_scaler.transform(X_mm_test)\n",
    "y_mm_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_mm_train = y_mm_scaler.fit_transform(y_mm_train.values.reshape(-1, 1))\n",
    "y_mm_test = y_mm_scaler.transform(y_mm_test.values.reshape(-1, 1))\n",
    "\n",
    "## convert to tensor\n",
    "X_mm_train_t = torch.tensor(X_mm_train, dtype=torch.float32)\n",
    "X_mm_test_t = torch.tensor(X_mm_test, dtype=torch.float32)\n",
    "y_mm_train_t = torch.tensor(y_mm_train, dtype=torch.float32)\n",
    "y_mm_test_t = torch.tensor(y_mm_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE.type == 'cuda':\n",
    "\t# move to DEVICE\n",
    "\tX_g_train_t = X_g_train_t.to(DEVICE)\n",
    "\ty_g_train_t = y_g_train_t.to(DEVICE)\n",
    "\tX_g_test_t = X_g_test_t.to(DEVICE)\n",
    "\ty_g_test_t = y_g_test_t.to(DEVICE)\n",
    "\n",
    "\tX_st_train_t = X_st_train_t.to(DEVICE)\n",
    "\ty_st_train_t = y_st_train_t.to(DEVICE)\n",
    "\tX_st_test_t = X_st_test_t.to(DEVICE)\n",
    "\ty_st_test_t = y_st_test_t.to(DEVICE)\n",
    "\n",
    "\tX_mm_train_t = X_mm_train_t.to(DEVICE)\n",
    "\ty_mm_train_t = y_mm_train_t.to(DEVICE)\n",
    "\tX_mm_test_t = X_mm_test_t.to(DEVICE)\n",
    "\ty_mm_test_t = y_mm_test_t.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardModel(nn.Module):\n",
    "\tdef __init__(self, input_dim, output_dim, dropout=0.1):\n",
    "\t\tsuper(FeedforwardModel, self).__init__()\n",
    "\t\t# layers\n",
    "\t\tself.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(32, output_dim),\n",
    "\t\t\tnn.ReLU()\n",
    "        )\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\tdef __init__(self, input_dim, model_dim, num_heads, num_layers, output_dim, dropout=0.1):\n",
    "\t\tsuper(TransformerModel, self).__init__()\n",
    "\t\t# layers\n",
    "\t\tself.embedding = nn.Linear(input_dim, model_dim)\n",
    "\t\tencoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, batch_first=True)\n",
    "\t\tself.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\t\tself.fc = nn.Linear(model_dim, output_dim)\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.embedding(x)\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = self.transformer(x)\n",
    "\t\tx = self.fc(x.mean(dim=1))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_scaling_pyt(y, y_scaler, d=False):\n",
    "    if d:\n",
    "        return y_scaler.inverse_transform(y.detach().cpu().numpy().reshape(-1, 1))\n",
    "    return y_scaler.inverse_transform(y.cpu().numpy().reshape(-1, 1))\n",
    "\n",
    "def inv_scaling(y, y_scaler):\n",
    "    return y_scaler.inverse_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = '../models/'\n",
    "models_path = {\n",
    "\t'general': {\n",
    "\t\t'tabnet': models_folder + 'tabnet/' + 'general.zip',\n",
    "\t\t'transformer': models_folder + 'transformer/' + 'general.pt',\n",
    "\t\t'feedforward': models_folder + 'feedforward/' + 'general.pt',\n",
    "\t\t'xgboost': models_folder + 'xgboost/' + 'general.json'\n",
    "\t},\n",
    "\t'single_thread': {\n",
    "\t\t'tabnet': models_folder + 'tabnet/' + 'single_thread.zip',\n",
    "\t\t'transformer': models_folder + 'transformer/' + 'single_thread.pt',\n",
    "\t\t'feedforward': models_folder + 'feedforward/' + 'single_thread.pt',\n",
    "\t\t'xgboost': models_folder + 'xgboost/' + 'single_thread.json'\n",
    "\t},\n",
    "\t'multi_thread': {\n",
    "\t\t'tabnet': models_folder + 'tabnet/' + 'multi_thread.zip',\n",
    "\t\t'transformer': models_folder + 'transformer/' + 'multi_thread.pt',\n",
    "\t\t'feedforward': models_folder + 'feedforward/' + 'multi_thread.pt',\n",
    "\t\t'xgboost': models_folder + 'xgboost/' + 'multi_thread.json'\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, X, X_t, y_scaler):\n",
    "\tpredictions = []\n",
    "\twith torch.no_grad():\n",
    "\t\tprediction = models[0](X_t)\n",
    "\t\tpredictions.append(inv_scaling_pyt(prediction, y_scaler))\n",
    "\tprediction = models[2].predict(X)\n",
    "\tpredictions.append(inv_scaling(prediction, y_scaler))\n",
    "\tprediction = models[3].predict(X)\n",
    "\tpredictions.append(inv_scaling(prediction, y_scaler))\n",
    "\tavg_predictions = np.mean(predictions, axis=0)\n",
    "\treturn avg_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frnk65/resource-prediction-study/venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# general models\n",
    "## TabNet\n",
    "g_tabnet = TabNetRegressor()\n",
    "g_tabnet.load_model(models_path['general']['tabnet'])\n",
    "## XGBoost\n",
    "g_xgboost = xgb.XGBRegressor()\n",
    "g_xgboost.load_model(models_path['general']['xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_g = [\n",
    "    torch.load(models_path[\"general\"][\"feedforward\"]).to(DEVICE),\n",
    "    torch.load(models_path[\"general\"][\"transformer\"]).to(DEVICE),\n",
    "    g_tabnet,\n",
    "    g_xgboost\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 318.57197552742275 - RMSE: 17.848584692558195 - MAE: 13.308869249539763\n"
     ]
    }
   ],
   "source": [
    "preds = ensemble_predict(models_g, X_g_test, X_g_test_t, y_g_scaler)\n",
    "y_scaled = inv_scaling(y_g_test, y_g_scaler)\n",
    "mse = mean_squared_error(y_scaled, preds)\n",
    "mae = mean_absolute_error(y_scaled, preds)\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frnk65/resource-prediction-study/venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# general models\n",
    "## TabNet\n",
    "st_tabnet = TabNetRegressor()\n",
    "st_tabnet.load_model(models_path['single_thread']['tabnet'])\n",
    "## XGBoost\n",
    "st_xgboost = xgb.XGBRegressor()\n",
    "st_xgboost.load_model(models_path['single_thread']['xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_st = [\n",
    "    torch.load(models_path[\"single_thread\"][\"feedforward\"]).to(DEVICE),\n",
    "    torch.load(models_path[\"single_thread\"][\"transformer\"]).to(DEVICE),\n",
    "    st_tabnet,\n",
    "    st_xgboost\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 250.89223979634184 - RMSE: 15.839578270785553 - MAE: 10.705123859011742\n"
     ]
    }
   ],
   "source": [
    "preds = ensemble_predict(models_st, X_st_test, X_st_test_t, y_st_scaler)\n",
    "y_scaled = inv_scaling(y_st_test, y_st_scaler)\n",
    "mse = mean_squared_error(y_scaled, preds)\n",
    "mae = mean_absolute_error(y_scaled, preds)\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frnk65/resource-prediction-study/venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# general models\n",
    "## TabNet\n",
    "mm_tabnet = TabNetRegressor()\n",
    "mm_tabnet.load_model(models_path['multi_thread']['tabnet'])\n",
    "## XGBoost\n",
    "mm_xgboost = xgb.XGBRegressor()\n",
    "mm_xgboost.load_model(models_path['multi_thread']['xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_mm = [\n",
    "    torch.load(models_path[\"multi_thread\"][\"feedforward\"]).to(DEVICE),\n",
    "    torch.load(models_path[\"multi_thread\"][\"transformer\"]).to(DEVICE),\n",
    "    mm_tabnet,\n",
    "    mm_xgboost\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 503.05628317175626 - RMSE: 22.428916228203185 - MAE: 22.395675151189163\n"
     ]
    }
   ],
   "source": [
    "preds = ensemble_predict(models_mm, X_mm_test, X_mm_test_t, y_mm_scaler)\n",
    "y_scaled = inv_scaling(y_mm_test, y_mm_scaler)\n",
    "mse = mean_squared_error(y_scaled, preds)\n",
    "mae = mean_absolute_error(y_scaled, preds)\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_val(model, X, X_t, y, y_scaler):\n",
    "\tmin_instance = {\"prediction\": float('inf'), \"actual\": 0, \"index\": 0}\n",
    "\tmax_instance = {\"prediction\": 0, \"actual\": 0, \"index\": 0}\n",
    "\t\n",
    "\tpredictions = ensemble_predict(model, X, X_t, y_scaler)\n",
    "\ty_scaled = inv_scaling(y, y_scaler)\n",
    "\tindex_min = np.argmin(np.abs(predictions - y_scaled))\n",
    "\tmin_instance[\"prediction\"] = predictions[index_min].item()\n",
    "\tmin_instance[\"actual\"] = y_scaled[index_min].item()\n",
    "\tmin_instance[\"index\"] = index_min\n",
    "\tindex_max = np.argmax(np.abs(predictions - y_scaled))\n",
    "\tmax_instance[\"prediction\"] = predictions[index_max].item()\n",
    "\tmax_instance[\"actual\"] = y_scaled[index_max].item()\n",
    "\tmax_instance[\"index\"] = index_max\n",
    "\n",
    "\treturn min_instance, max_instance, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set general model\n",
      "Mean prediction: 22.28175163269043 | Std actual: 18.877511978149414\n",
      "Mean actual: 35.041486486486484 | Std actual: 28.83706408578472\n",
      "Mean Error: 13.308869249539763 | Std Error: 11.893106189136534\n",
      "---\n",
      "Min instance\n",
      "total_time                                                       12.97\n",
      "total_cpu_usage                                                   0.99\n",
      "max_ram_usage                                              1436.332031\n",
      "brand_raw                         12th Gen Intel(R) Core(TM) i5-12400F\n",
      "count                                                               12\n",
      "l2_cache_size                                                      7.5\n",
      "l3_cache_size                                                     18.0\n",
      "l2_cache_line_size                                                1280\n",
      "l2_cache_associativity                                               7\n",
      "benchmark                                                          KNP\n",
      "ghz_actual_friendly                                              2.496\n",
      "ghz_advertised_friendly                                          2.496\n",
      "total_time_target                                                18.11\n",
      "brand_raw_target                   13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                        12\n",
      "l2_cache_size_target                                               7.5\n",
      "l3_cache_size_target                                              12.0\n",
      "l2_cache_line_size_target                                         1280\n",
      "l2_cache_associativity_target                                        7\n",
      "ghz_advertised_friendly_target                                   2.496\n",
      "Name: 4033, dtype: object\n",
      "Min Prediction: 16.95671272277832 | Actual: 18.11 | Error: 1.1532872772216791\n",
      "---\n",
      "Max instance\n",
      "total_time                                                          106.93\n",
      "total_cpu_usage                                                       0.99\n",
      "max_ram_usage                                                         15.5\n",
      "brand_raw                         Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz\n",
      "count                                                                   12\n",
      "l2_cache_size                                                          1.5\n",
      "l3_cache_size                                                         12.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                        N_Queens2\n",
      "ghz_actual_friendly                                                    4.0\n",
      "ghz_advertised_friendly                                                2.9\n",
      "total_time_target                                                   155.04\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 1757, dtype: object\n",
      "Max Prediction: 96.4735336303711 | Actual: 155.04 | Error: 58.5664663696289\n"
     ]
    }
   ],
   "source": [
    "# general model\n",
    "print(\"Validation set general model\")\n",
    "min_instance, max_instance, predictions = describe_val(models_g, X_g_test, X_g_test_t, y_g_test, y_g_scaler)\n",
    "y_scaled = inv_scaling(y_g_test, y_g_scaler)\n",
    "errors = np.abs(predictions - y_scaled)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_scaled)} | Std actual: {np.std(y_scaled)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"---\")\n",
    "print(\"Min instance\")\n",
    "print(g_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(g_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set single thread model\n",
      "Mean prediction: 24.895668029785156 | Std actual: 20.056520462036133\n",
      "Mean actual: 34.75261290322581 | Std actual: 31.49396398818138\n",
      "Mean Error: 10.705123859011742 | Std Error: 11.674440584437413\n",
      "---\n",
      "Min instance\n",
      "total_time                                                          107.06\n",
      "total_cpu_usage                                                       0.99\n",
      "max_ram_usage                                                       15.125\n",
      "brand_raw                         Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz\n",
      "count                                                                   12\n",
      "l2_cache_size                                                          1.5\n",
      "l3_cache_size                                                         12.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                        N_Queens2\n",
      "ghz_actual_friendly                                                    4.0\n",
      "ghz_advertised_friendly                                                2.9\n",
      "total_time_target                                                   154.65\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 1778, dtype: object\n",
      "Min Prediction: 18.04050636291504 | Actual: 18.11 | Error: 0.06949363708496037\n",
      "---\n",
      "Max instance\n",
      "total_time                                                                 10.76\n",
      "total_cpu_usage                                                             0.99\n",
      "max_ram_usage                                                          37.742188\n",
      "brand_raw                         11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz\n",
      "count                                                                          8\n",
      "l2_cache_size                                                                5.0\n",
      "l3_cache_size                                                                8.0\n",
      "l2_cache_line_size                                                           256\n",
      "l2_cache_associativity                                                         7\n",
      "benchmark                                                                   TSP2\n",
      "ghz_actual_friendly                                                       2.4192\n",
      "ghz_advertised_friendly                                                      2.4\n",
      "total_time_target                                                           7.39\n",
      "brand_raw_target                             13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                                  12\n",
      "l2_cache_size_target                                                         7.5\n",
      "l3_cache_size_target                                                        12.0\n",
      "l2_cache_line_size_target                                                   1280\n",
      "l2_cache_associativity_target                                                  7\n",
      "ghz_advertised_friendly_target                                             2.496\n",
      "Name: 7572, dtype: object\n",
      "Max Prediction: 100.3192367553711 | Actual: 155.04 | Error: 54.7207632446289\n"
     ]
    }
   ],
   "source": [
    "# single thread model\n",
    "print(\"Validation set single thread model\")\n",
    "min_instance, max_instance, predictions = describe_val(models_st, X_st_test, X_st_test_t, y_st_test, y_st_scaler)\n",
    "y_scaled = inv_scaling(y_st_test, y_st_scaler)\n",
    "errors = np.abs(predictions - y_scaled)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_scaled)} | Std actual: {np.std(y_scaled)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"---\")\n",
    "print(\"Min instance\")\n",
    "print(g_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(g_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set multi thread model\n",
      "Mean prediction: 14.138323783874512 | Std actual: 0.8692489266395569\n",
      "Mean actual: 36.534 | Std actual: 0.8569854141115829\n",
      "Mean Error: 22.395675151189163 | Std Error: 1.2206628093639538\n",
      "---\n",
      "Min instance\n",
      "total_time                                                           17.33\n",
      "total_cpu_usage                                                       0.99\n",
      "max_ram_usage                                                       15.625\n",
      "brand_raw                         Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz\n",
      "count                                                                   12\n",
      "l2_cache_size                                                          1.5\n",
      "l3_cache_size                                                         12.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                         N_Queens\n",
      "ghz_actual_friendly                                                 4.0438\n",
      "ghz_advertised_friendly                                                2.9\n",
      "total_time_target                                                    25.02\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 659, dtype: object\n",
      "Min Prediction: 15.7760591506958 | Actual: 35.58 | Error: 19.803940849304198\n",
      "---\n",
      "Max instance\n",
      "total_time                                                            51.3\n",
      "total_cpu_usage                                                       0.99\n",
      "max_ram_usage                                                     83.34375\n",
      "brand_raw                         Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz\n",
      "count                                                                   12\n",
      "l2_cache_size                                                          1.5\n",
      "l3_cache_size                                                         12.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                             TSP4\n",
      "ghz_actual_friendly                                                 4.0011\n",
      "ghz_advertised_friendly                                                2.9\n",
      "total_time_target                                                    65.66\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 1530, dtype: object\n",
      "Max Prediction: 12.30457592010498 | Actual: 38.02 | Error: 25.715424079895023\n"
     ]
    }
   ],
   "source": [
    "# multi thread model\n",
    "print(\"Validation set multi thread model\")\n",
    "min_instance, max_instance, predictions = describe_val(models_mm, X_mm_test, X_mm_test_t, y_mm_test, y_mm_scaler)\n",
    "y_scaled = inv_scaling(y_mm_test, y_mm_scaler)\n",
    "errors = np.abs(predictions - y_scaled)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_scaled)} | Std actual: {np.std(y_scaled)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"---\")\n",
    "print(\"Min instance\")\n",
    "print(g_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(g_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
