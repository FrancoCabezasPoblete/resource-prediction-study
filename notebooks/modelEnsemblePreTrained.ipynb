{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "#from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if DEVICE.type == 'cuda':\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_to_MiB(row):\n",
    "\t# verify if has string ' MiB'\n",
    "\tif 'MiB' in str(row):\n",
    "\t\trow = row.replace(' MiB', '')\n",
    "\t\trow = float(row)\n",
    "\telse:\n",
    "\t\trow = float(row) / np.power(2, 20)\n",
    "\treturn row\n",
    "\n",
    "\n",
    "def MHz_to_GHz(row):\n",
    "\t# verify if has string ' GHz'\n",
    "\tif 'GHz' in str(row):\n",
    "\t\trow = row.replace(' GHz', '')\n",
    "\t\t# convert to float\n",
    "\t\trow = float(row)\n",
    "\telse:\n",
    "\t\trow = row.replace(' MHz', '')\n",
    "\t\trow = float(row) / 1000\n",
    "\treturn row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('../results_new/execution_time.csv')\n",
    "results_savio_df = pd.read_csv('../results_savio_new/execution_time.csv')\n",
    "results_df = pd.concat([results_df, results_savio_df], ignore_index=True)\n",
    "# preprocessing\n",
    "results_df['total_cpu_usage'] = results_df['total_cpu_usage'].str.replace('%', '').astype(float) / 100\n",
    "results_df['max_ram_usage'] = results_df['max_ram_usage'] / 1024\n",
    "results_df['l2_cache_size'] = results_df['l2_cache_size'].apply(bits_to_MiB)\n",
    "results_df['l3_cache_size'] = results_df['l3_cache_size'].apply(bits_to_MiB)\n",
    "results_df['ghz_actual_friendly'] = results_df['hz_actual_friendly'].apply(MHz_to_GHz)\n",
    "results_df['ghz_advertised_friendly'] = results_df['hz_advertised_friendly'].str.replace('GHz', '').astype(float)\n",
    "results_df = results_df.drop(columns=['hz_actual_friendly', 'hz_advertised_friendly', 'arch', 'vendor_id_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "      <th>total_cpu_usage</th>\n",
       "      <th>max_ram_usage</th>\n",
       "      <th>brand_raw</th>\n",
       "      <th>count</th>\n",
       "      <th>l2_cache_size</th>\n",
       "      <th>l3_cache_size</th>\n",
       "      <th>l2_cache_line_size</th>\n",
       "      <th>l2_cache_associativity</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>ghz_actual_friendly</th>\n",
       "      <th>ghz_advertised_friendly</th>\n",
       "      <th>total_time_target</th>\n",
       "      <th>brand_raw_target</th>\n",
       "      <th>count_target</th>\n",
       "      <th>l2_cache_size_target</th>\n",
       "      <th>l3_cache_size_target</th>\n",
       "      <th>l2_cache_line_size_target</th>\n",
       "      <th>l2_cache_associativity_target</th>\n",
       "      <th>ghz_advertised_friendly_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1436.714844</td>\n",
       "      <td>Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>KNP</td>\n",
       "      <td>4.1729</td>\n",
       "      <td>2.9</td>\n",
       "      <td>45.91</td>\n",
       "      <td>13th Gen Intel(R) Core(TM) i5-1335U</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>7</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1436.714844</td>\n",
       "      <td>Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>KNP</td>\n",
       "      <td>4.1729</td>\n",
       "      <td>2.9</td>\n",
       "      <td>25.77</td>\n",
       "      <td>13th Gen Intel(R) Core(TM) i5-1335U</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>7</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_time  total_cpu_usage  max_ram_usage  \\\n",
       "5       13.47             0.99    1436.714844   \n",
       "6       13.47             0.99    1436.714844   \n",
       "\n",
       "                                  brand_raw  count  l2_cache_size  \\\n",
       "5  Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz     12            1.5   \n",
       "6  Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz     12            1.5   \n",
       "\n",
       "   l3_cache_size  l2_cache_line_size  l2_cache_associativity benchmark  \\\n",
       "5           12.0                 256                       6       KNP   \n",
       "6           12.0                 256                       6       KNP   \n",
       "\n",
       "   ghz_actual_friendly  ghz_advertised_friendly  total_time_target  \\\n",
       "5               4.1729                      2.9              45.91   \n",
       "6               4.1729                      2.9              25.77   \n",
       "\n",
       "                      brand_raw_target  count_target  l2_cache_size_target  \\\n",
       "5  13th Gen Intel(R) Core(TM) i5-1335U            12                   7.5   \n",
       "6  13th Gen Intel(R) Core(TM) i5-1335U            12                   7.5   \n",
       "\n",
       "   l3_cache_size_target  l2_cache_line_size_target  \\\n",
       "5                  12.0                       1280   \n",
       "6                  12.0                       1280   \n",
       "\n",
       "   l2_cache_associativity_target  ghz_advertised_friendly_target  \n",
       "5                              7                           2.496  \n",
       "6                              7                           2.496  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the target dataset\n",
    "target_df = results_df[['total_time', 'brand_raw', 'count', 'l2_cache_size', 'l3_cache_size', 'l2_cache_line_size', 'l2_cache_associativity', 'ghz_advertised_friendly', 'benchmark']].copy()\n",
    "# Rename columns to *_target\n",
    "target_df = target_df.rename(columns={\n",
    "    'total_time': 'total_time_target',\n",
    "    'brand_raw': 'brand_raw_target',\n",
    "    'count': 'count_target',\n",
    "    'l2_cache_size': 'l2_cache_size_target',\n",
    "    'l3_cache_size': 'l3_cache_size_target',\n",
    "    'l2_cache_line_size': 'l2_cache_line_size_target',\n",
    "    'l2_cache_associativity': 'l2_cache_associativity_target',\n",
    "    'ghz_advertised_friendly': 'ghz_advertised_friendly_target',\n",
    "})\n",
    "\n",
    "dataset_df = pd.merge(results_df, target_df, how='inner', on='benchmark')\n",
    "dataset_df = dataset_df[dataset_df['brand_raw'] != dataset_df['brand_raw_target']]\n",
    "dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove one computer for testing\n",
    "g_train = dataset_df[(dataset_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (dataset_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "g_test = dataset_df[dataset_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df = dataset_df[dataset_df['benchmark'].isin(['MATRIX_MULT', 'MATRIX_MULT2', 'MATRIX_MULT3'])]\n",
    "# remove one computer for testing\n",
    "mm_train = mm_df[(mm_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (mm_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "mm_test = mm_df[mm_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df = dataset_df[~dataset_df['benchmark'].isin(['MATRIX_MULT', 'MATRIX_MULT2', 'MATRIX_MULT3'])]\n",
    "# remove one computer for testing\n",
    "st_train = st_df[(st_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (st_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "st_test = st_df[st_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "g_test = pd.read_csv('csv/g_test.csv')\n",
    "st_test = pd.read_csv('csv/st_test.csv')\n",
    "mm_test = pd.read_csv('csv/mm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'total_time_target'\n",
    "features = mm_test.columns.copy().drop(target).drop(['benchmark','brand_raw', 'brand_raw_target'])\n",
    "features_st = features.copy().drop(['count', 'count_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general data\n",
    "## split data\n",
    "X_g_train = g_train[features]\n",
    "y_g_train = g_train[target]\n",
    "\n",
    "X_g_test = g_test[features]\n",
    "y_g_test = g_test[target]\n",
    "\n",
    "## normalize data\n",
    "scaler_g = StandardScaler()\n",
    "X_g_train = scaler_g.fit_transform(X_g_train)\n",
    "X_g_test = scaler_g.transform(X_g_test)\n",
    "\n",
    "## convert to tensor\n",
    "X_g_train_t = torch.tensor(X_g_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_g_test_t = torch.tensor(X_g_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_g_train_t = torch.tensor(y_g_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_g_test_t = torch.tensor(y_g_test.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single thread data\n",
    "## split data\n",
    "X_st_train = st_train[features_st]\n",
    "y_st_train = st_train[target]\n",
    "\n",
    "X_st_test = st_test[features_st]\n",
    "y_st_test = st_test[target]\n",
    "\n",
    "## normalize data\n",
    "scaler_st = StandardScaler()\n",
    "X_st_train = scaler_st.fit_transform(X_st_train)\n",
    "X_st_test = scaler_st.transform(X_st_test)\n",
    "\n",
    "## convert to tensor\n",
    "X_st_train_t = torch.tensor(X_st_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_st_test_t = torch.tensor(X_st_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_st_train_t = torch.tensor(y_st_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_st_test_t = torch.tensor(y_st_test.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi thread data\n",
    "## split data\n",
    "X_mm_train = mm_train[features]\n",
    "y_mm_train = mm_train[target]\n",
    "\n",
    "X_mm_test = mm_test[features]\n",
    "y_mm_test = mm_test[target]\n",
    "\n",
    "## normalize data\n",
    "scaler_mm = StandardScaler()\n",
    "X_mm_train = scaler_mm.fit_transform(X_mm_train)\n",
    "X_mm_test = scaler_mm.transform(X_mm_test)\n",
    "\n",
    "## convert to tensor\n",
    "X_mm_train_t = torch.tensor(X_mm_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_mm_test_t = torch.tensor(X_mm_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_mm_train_t = torch.tensor(y_mm_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_mm_test_t = torch.tensor(y_mm_test.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE.type == 'cuda':\n",
    "\t# move to DEVICE\n",
    "\tX_g_train_t = X_g_train_t.to(DEVICE)\n",
    "\ty_g_train_t = y_g_train_t.to(DEVICE)\n",
    "\tX_g_test_t = X_g_test_t.to(DEVICE)\n",
    "\ty_g_test_t = y_g_test_t.to(DEVICE)\n",
    "\n",
    "\tX_st_train_t = X_st_train_t.to(DEVICE)\n",
    "\ty_st_train_t = y_st_train_t.to(DEVICE)\n",
    "\tX_st_test_t = X_st_test_t.to(DEVICE)\n",
    "\ty_st_test_t = y_st_test_t.to(DEVICE)\n",
    "\n",
    "\tX_mm_train_t = X_mm_train_t.to(DEVICE)\n",
    "\ty_mm_train_t = y_mm_train_t.to(DEVICE)\n",
    "\tX_mm_test_t = X_mm_test_t.to(DEVICE)\n",
    "\ty_mm_test_t = y_mm_test_t.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardModel(nn.Module):\n",
    "\tdef __init__(self, input_dim, output_dim, dropout=0.1):\n",
    "\t\tsuper(FeedforwardModel, self).__init__()\n",
    "\t\t# layers\n",
    "\t\tself.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x).view(-1,1)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\tdef __init__(self, input_dim, model_dim, num_heads, num_layers, output_dim, dropout=0.1):\n",
    "\t\tsuper(TransformerModel, self).__init__()\n",
    "\t\t# layers\n",
    "\t\tself.embedding = nn.Linear(input_dim, model_dim)\n",
    "\t\tencoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, batch_first=True)\n",
    "\t\tself.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\t\tself.fc = nn.Linear(model_dim, output_dim)\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.embedding(x)\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = self.transformer(x)\n",
    "\t\tx = self.fc(x.mean(dim=1))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = '../models/'\n",
    "models_path = {\n",
    "\t'general': {\n",
    "\t\t'tabnet': models_folder + 'tabnet/' + 'general.zip',\n",
    "\t\t'transformer': models_folder + 'transformer/' + 'general.pt',\n",
    "\t\t'feedforward': models_folder + 'feedforward/' + 'general.pt',\n",
    "\t\t'xgboost': models_folder + 'xgboost/' + 'general.json'\n",
    "\t},\n",
    "\t'single_thread': {\n",
    "\t\t'tabnet': models_folder + 'tabnet/' + 'single_thread.zip',\n",
    "\t\t'transformer': models_folder + 'transformer/' + 'single_thread.pt',\n",
    "\t\t'feedforward': models_folder + 'feedforward/' + 'single_thread.pt',\n",
    "\t\t'xgboost': models_folder + 'xgboost/' + 'single_thread.json'\n",
    "\t},\n",
    "\t'multi_thread': {\n",
    "\t\t'tabnet': models_folder + 'tabnet/' + 'multi_thread.zip',\n",
    "\t\t'transformer': models_folder + 'transformer/' + 'multi_thread.pt',\n",
    "\t\t'feedforward': models_folder + 'feedforward/' + 'multi_thread.pt',\n",
    "\t\t'xgboost': models_folder + 'xgboost/' + 'multi_thread.json'\n",
    "\t}\n",
    "}\n",
    "scalers_path = {\n",
    "\t'general': models_folder + 'scaler_g.joblib',\n",
    "\t'single_thread': models_folder + 'scaler_st.joblib',\n",
    "\t'multi_thread': models_folder + 'scaler_mm.joblib'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, X, X_t):\n",
    "\tpredictions = []\n",
    "\twith torch.no_grad():\n",
    "\t\tprint(models[0].model[0])\n",
    "\t\tprint(X_t.shape)\n",
    "\t\tpredictions.append(models[0](X_t).cpu().numpy().flatten())\n",
    "\tpredictions.append(models[2].predict(X).flatten())\n",
    "\tpredictions.append(models[3].predict(X).flatten())\n",
    "\tavg_predictions = np.mean(predictions, axis=0)\n",
    "\treturn avg_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(scaler_g, f'{models_folder}/scaler_g.joblib')\n",
    "#dump(scaler_st, f'{models_folder}/scaler_st.joblib')\n",
    "#dump(scaler_mm, f'{models_folder}/scaler_mm.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frnk65/resource-prediction-study/venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# general models\n",
    "## TabNet\n",
    "g_tabnet = TabNetRegressor()\n",
    "g_tabnet.load_model(models_path['general']['tabnet'])\n",
    "## XGBoost\n",
    "g_xgboost = xgb.XGBRegressor()\n",
    "g_xgboost.load_model(models_path['general']['xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_g = [\n",
    "    torch.load(models_path[\"general\"][\"feedforward\"]).to(DEVICE),\n",
    "    torch.load(models_path[\"general\"][\"transformer\"]).to(DEVICE),\n",
    "    g_tabnet,\n",
    "    g_xgboost\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=16, out_features=64, bias=True)\n",
      "torch.Size([900, 1, 16])\n",
      "MSE: 97.95959151197678 - RMSE: 9.897453789332728 - MAE: 6.771173392910427\n"
     ]
    }
   ],
   "source": [
    "preds = ensemble_predict(models_g, X_g_test, X_g_test_t)\n",
    "mse = mean_squared_error(y_g_test, preds)\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mean_absolute_error(y_g_test, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frnk65/resource-prediction-study/venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# general models\n",
    "## TabNet\n",
    "st_tabnet = TabNetRegressor()\n",
    "st_tabnet.load_model(models_path['single_thread']['tabnet'])\n",
    "## XGBoost\n",
    "st_xgboost = xgb.XGBRegressor()\n",
    "st_xgboost.load_model(models_path['single_thread']['xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_st = [\n",
    "    torch.load(models_path[\"single_thread\"][\"feedforward\"]).to(DEVICE),\n",
    "    torch.load(models_path[\"single_thread\"][\"transformer\"]).to(DEVICE),\n",
    "    st_tabnet,\n",
    "    st_xgboost\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=14, out_features=64, bias=True)\n",
      "torch.Size([675, 1, 14])\n",
      "MSE: 56.74999736758766 - RMSE: 7.533259411940336 - MAE: 4.2718147920961735\n"
     ]
    }
   ],
   "source": [
    "preds = ensemble_predict(models_st, X_st_test, X_st_test_t)\n",
    "mse = mean_squared_error(y_st_test, preds)\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mean_absolute_error(y_st_test, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frnk65/resource-prediction-study/venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# general models\n",
    "## TabNet\n",
    "mm_tabnet = TabNetRegressor()\n",
    "mm_tabnet.load_model(models_path['multi_thread']['tabnet'])\n",
    "## XGBoost\n",
    "mm_xgboost = xgb.XGBRegressor()\n",
    "mm_xgboost.load_model(models_path['multi_thread']['xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_mm = [\n",
    "    torch.load(models_path[\"multi_thread\"][\"feedforward\"]).to(DEVICE),\n",
    "    torch.load(models_path[\"multi_thread\"][\"transformer\"]).to(DEVICE),\n",
    "    mm_tabnet,\n",
    "    mm_xgboost\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=16, out_features=64, bias=True)\n",
      "torch.Size([225, 1, 16])\n",
      "MSE: 492.0993801494934 - RMSE: 22.183313101281634 - MAE: 22.010240815056694\n"
     ]
    }
   ],
   "source": [
    "preds = ensemble_predict(models_mm, X_mm_test, X_mm_test_t)\n",
    "mse = mean_squared_error(y_mm_test, preds)\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mean_absolute_error(y_mm_test, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_val(model, X, X_t, y):\n",
    "\tmin_instance = {\"prediction\": float('inf'), \"actual\": 0, \"index\": 0}\n",
    "\tmax_instance = {\"prediction\": 0, \"actual\": 0, \"index\": 0}\n",
    "\t\n",
    "\tpredictions = ensemble_predict(model, X, X_t)\n",
    "\tindex_min = np.argmin(np.abs(predictions - y))\n",
    "\tmin_instance[\"prediction\"] = predictions[index_min]\n",
    "\tmin_instance[\"actual\"] = y[index_min]\n",
    "\tmin_instance[\"index\"] = index_min\n",
    "\tindex_max = np.argmax(np.abs(predictions - y))\n",
    "\tmax_instance[\"prediction\"] = predictions[index_max]\n",
    "\tmax_instance[\"actual\"] = y[index_max]\n",
    "\tmax_instance[\"index\"] = index_max\n",
    "\n",
    "\treturn min_instance, max_instance, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set general model\n",
      "Linear(in_features=16, out_features=64, bias=True)\n",
      "torch.Size([900, 1, 16])\n",
      "Mean prediction: 23.126462936401367 | Std actual: 3.2905521392822266\n",
      "Mean actual: 27.556500000000003 | Std actual: 7.4113266524961645\n",
      "Mean Error: 6.771173392910427 | Std Error: 7.218781226434187\n",
      "---\n",
      "Min instance\n",
      "total_time                                                            24.22\n",
      "total_cpu_usage                                                        0.99\n",
      "max_ram_usage                                                     25.316406\n",
      "brand_raw                         Intel(R) Xeon(R) CPU E5-2670 v3 @ 2.30GHz\n",
      "count                                                                    24\n",
      "l2_cache_size                                                           6.0\n",
      "l3_cache_size                                                          30.0\n",
      "l2_cache_line_size                                                      256\n",
      "l2_cache_associativity                                                    6\n",
      "benchmark                                                               TSP\n",
      "ghz_actual_friendly                                                     1.2\n",
      "ghz_advertised_friendly                                                 2.3\n",
      "total_time_target                                                      23.3\n",
      "brand_raw_target                        13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                             12\n",
      "l2_cache_size_target                                                    7.5\n",
      "l3_cache_size_target                                                   12.0\n",
      "l2_cache_line_size_target                                              1280\n",
      "l2_cache_associativity_target                                             7\n",
      "ghz_advertised_friendly_target                                        2.496\n",
      "Name: 572, dtype: object\n",
      "Min Prediction: 23.30609893798828 | Actual: 23.3 | Error: 0.0060989379882805395\n",
      "---\n",
      "Max instance\n",
      "total_time                                                            15.28\n",
      "total_cpu_usage                                                        0.99\n",
      "max_ram_usage                                                   1436.171875\n",
      "brand_raw                         Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz\n",
      "count                                                                     8\n",
      "l2_cache_size                                                           1.0\n",
      "l3_cache_size                                                           8.0\n",
      "l2_cache_line_size                                                      256\n",
      "l2_cache_associativity                                                    6\n",
      "benchmark                                                               KNP\n",
      "ghz_actual_friendly                                                   2.496\n",
      "ghz_advertised_friendly                                                 2.5\n",
      "total_time_target                                                     45.91\n",
      "brand_raw_target                        13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                             12\n",
      "l2_cache_size_target                                                    7.5\n",
      "l3_cache_size_target                                                   12.0\n",
      "l2_cache_line_size_target                                              1280\n",
      "l2_cache_associativity_target                                             7\n",
      "ghz_advertised_friendly_target                                        2.496\n",
      "Name: 420, dtype: object\n",
      "Max Prediction: 20.062070846557617 | Actual: 45.91 | Error: 25.84792915344238\n"
     ]
    }
   ],
   "source": [
    "# general model\n",
    "print(\"Validation set general model\")\n",
    "min_instance, max_instance, predictions = describe_val(models_g, X_g_test, X_g_test_t, y_g_test)\n",
    "errors = np.abs(predictions - y_g_test)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_g_test)} | Std actual: {np.std(y_g_test)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"---\")\n",
    "print(\"Min instance\")\n",
    "print(g_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(g_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set single thread model\n",
      "Linear(in_features=14, out_features=64, bias=True)\n",
      "torch.Size([675, 1, 14])\n",
      "Mean prediction: 23.79733657836914 | Std actual: 3.99114727973938\n",
      "Mean actual: 24.564000000000007 | Std actual: 6.096883138128859\n",
      "Mean Error: 4.2718147920961735 | Std Error: 6.204965410831554\n",
      "Min instance\n",
      "total_time                                                           24.81\n",
      "total_cpu_usage                                                        1.0\n",
      "max_ram_usage                                                    31.253906\n",
      "brand_raw                         Intel(R) Core(TM) i5-8300H CPU @ 2.30GHz\n",
      "count                                                                    8\n",
      "l2_cache_size                                                          1.0\n",
      "l3_cache_size                                                          8.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                              TSP\n",
      "ghz_actual_friendly                                                  2.304\n",
      "ghz_advertised_friendly                                                2.3\n",
      "total_time_target                                                    22.63\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 296, dtype: object\n",
      "Min Prediction: 22.629518508911133 | Actual: 22.63 | Error: 0.00048149108886619274\n",
      "---\n",
      "Max instance\n",
      "total_time                                                            15.54\n",
      "total_cpu_usage                                                        0.99\n",
      "max_ram_usage                                                   1435.285156\n",
      "brand_raw                         Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz\n",
      "count                                                                     8\n",
      "l2_cache_size                                                           1.0\n",
      "l3_cache_size                                                           8.0\n",
      "l2_cache_line_size                                                      256\n",
      "l2_cache_associativity                                                    6\n",
      "benchmark                                                               KNP\n",
      "ghz_actual_friendly                                                   2.496\n",
      "ghz_advertised_friendly                                                 2.5\n",
      "total_time_target                                                     45.91\n",
      "brand_raw_target                        13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                             12\n",
      "l2_cache_size_target                                                    7.5\n",
      "l3_cache_size_target                                                   12.0\n",
      "l2_cache_line_size_target                                              1280\n",
      "l2_cache_associativity_target                                             7\n",
      "ghz_advertised_friendly_target                                        2.496\n",
      "Name: 305, dtype: object\n",
      "Max Prediction: 17.706510543823242 | Actual: 45.91 | Error: 28.203489456176754\n"
     ]
    }
   ],
   "source": [
    "# single thread model\n",
    "print(\"Validation set single thread model\")\n",
    "min_instance, max_instance, predictions = describe_val(models_st, X_st_test, X_st_test_t, y_st_test)\n",
    "errors = np.abs(predictions - y_st_test)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_st_test)} | Std actual: {np.std(y_st_test)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"Min instance\")\n",
    "print(st_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(st_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set multi thread model\n",
      "Linear(in_features=16, out_features=64, bias=True)\n",
      "torch.Size([225, 1, 16])\n",
      "Mean prediction: 14.523759841918945 | Std actual: 2.6294972896575928\n",
      "Mean actual: 36.534 | Std actual: 0.8569854141115829\n",
      "Mean Error: 22.010240815056694 | Std Error: 2.7656245972123217\n",
      "Min instance\n",
      "total_time                                                            26.65\n",
      "total_cpu_usage                                                        1.92\n",
      "max_ram_usage                                                   2333.460938\n",
      "brand_raw                         Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz\n",
      "count                                                                     8\n",
      "l2_cache_size                                                           2.0\n",
      "l3_cache_size                                                          10.0\n",
      "l2_cache_line_size                                                      256\n",
      "l2_cache_associativity                                                    2\n",
      "benchmark                                                       MATRIX_MULT\n",
      "ghz_actual_friendly                                                  3.0005\n",
      "ghz_advertised_friendly                                                 3.0\n",
      "total_time_target                                                     35.58\n",
      "brand_raw_target                        13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                             12\n",
      "l2_cache_size_target                                                    7.5\n",
      "l3_cache_size_target                                                   12.0\n",
      "l2_cache_line_size_target                                              1280\n",
      "l2_cache_associativity_target                                             7\n",
      "ghz_advertised_friendly_target                                        2.496\n",
      "Name: 159, dtype: object\n",
      "Min Prediction: 19.0046443939209 | Actual: 35.58 | Error: 16.5753556060791\n",
      "---\n",
      "Max instance\n",
      "total_time                                                            3.74\n",
      "total_cpu_usage                                                      22.66\n",
      "max_ram_usage                                                  2380.378906\n",
      "brand_raw                         Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz\n",
      "count                                                                   40\n",
      "l2_cache_size                                                         40.0\n",
      "l3_cache_size                                                         27.5\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                      MATRIX_MULT\n",
      "ghz_actual_friendly                                                0.95592\n",
      "ghz_advertised_friendly                                                2.1\n",
      "total_time_target                                                    38.02\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 195, dtype: object\n",
      "Max Prediction: 10.467986106872559 | Actual: 38.02 | Error: 27.552013893127445\n"
     ]
    }
   ],
   "source": [
    "# multi thread model\n",
    "print(\"Validation set multi thread model\")\n",
    "min_instance, max_instance, predictions = describe_val(models_mm, X_mm_test, X_mm_test_t, y_mm_test)\n",
    "errors = np.abs(predictions - y_mm_test)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_mm_test)} | Std actual: {np.std(y_mm_test)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"Min instance\")\n",
    "print(mm_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(mm_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
