{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import random\n",
    "import os\n",
    "from joblib import dump\n",
    "\n",
    "# CUDA\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE.type)\n",
    "\n",
    "# Fix random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if DEVICE.type == 'cuda':\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df and test_df are created in eda notebook\n",
    "if not os.path.exists('csv/train_df.csv') or not os.path.exists('csv/test_df.csv'):\n",
    "\tprint('Please run the eda notebook first')\n",
    "\texit()\n",
    "train_df = pd.read_csv('csv/train_df.csv')\n",
    "test_df = pd.read_csv('csv/test_df.csv')\n",
    "target = 'total_time_target'\n",
    "features = test_df.columns.copy().drop(target).drop(['benchmark','brand_raw', 'brand_raw_target','vendor_id_raw', 'arch'])\n",
    "\n",
    "# log for total_times\n",
    "train_df_log = train_df.copy()\n",
    "test_df_log = test_df.copy()\n",
    "train_df_log[[target, 'total_time']] = np.log1p(train_df[[target, 'total_time']])\n",
    "test_df_log[[target, 'total_time']] = np.log1p(test_df[[target, 'total_time']])\n",
    "\n",
    "# Split data\n",
    "## XGB & MCD\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target]\n",
    "\n",
    "# Normalize data\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = x_scaler.fit_transform(X_train)\n",
    "X_test = x_scaler.transform(X_test)\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_train = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "## convert to tensor\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "if DEVICE.type == 'cuda':\n",
    "\tX_train_t = X_train_t.to(DEVICE)\n",
    "\ty_train_t = y_train_t.to(DEVICE)\n",
    "\tX_test_t = X_test_t.to(DEVICE)\n",
    "\ty_test_t = y_test_t.to(DEVICE)\n",
    "\n",
    "## TabNet & FNN\n",
    "X_train_log = train_df_log[features]\n",
    "y_train_log = train_df_log[target]\n",
    "\n",
    "X_test_log = test_df_log[features]\n",
    "y_test_log = test_df_log[target]\n",
    "\n",
    "# Normalize data\n",
    "x_scaler_log = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_log = x_scaler_log.fit_transform(X_train_log)\n",
    "X_test_log = x_scaler_log.transform(X_test_log)\n",
    "\n",
    "y_scaler_log = MinMaxScaler(feature_range=(0, 1))\n",
    "y_train_log = y_scaler_log.fit_transform(y_train_log.values.reshape(-1, 1))\n",
    "y_test_log = y_scaler_log.transform(y_test_log.values.reshape(-1, 1))\n",
    "\n",
    "## convert to tensor\n",
    "X_train_t_log = torch.tensor(X_train_log, dtype=torch.float32)\n",
    "X_test_t_log = torch.tensor(X_test_log, dtype=torch.float32)\n",
    "y_train_t_log = torch.tensor(y_train_log, dtype=torch.float32)\n",
    "y_test_t_log = torch.tensor(y_test_log, dtype=torch.float32)\n",
    "\n",
    "if DEVICE.type == 'cuda':\n",
    "\tX_train_t_log = X_train_t_log.to(DEVICE)\n",
    "\ty_train_t_log = y_train_t_log.to(DEVICE)\n",
    "\tX_test_t_log = X_test_t_log.to(DEVICE)\n",
    "\ty_test_t_log = y_test_t_log.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../models/x_scaler.joblib') or not os.path.exists('../models/y_scaler.joblib'):\n",
    "\tdump(x_scaler, '../models/x_scaler.joblib')\n",
    "\tdump(y_scaler, '../models/y_scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardModel(nn.Module):\n",
    "\tdef __init__(self, input_dim, dropout=0.1):\n",
    "\t\tsuper(FeedforwardModel, self).__init__()\n",
    "\t\t# layers\n",
    "\t\tself.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "\t\t\tnn.Linear(64, 32),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=dropout),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)\n",
    "\t\n",
    "\tdef predict(model, X):\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tprediction = model(X)\n",
    "\t\treturn prediction\n",
    "\t\n",
    "class MCDropoutModel(nn.Module):\n",
    "\tdef __init__(self, input_dim, n_hidden_layers, dropout=0.1):\n",
    "\t\tsuper(MCDropoutModel, self).__init__()\n",
    "\t\tif n_hidden_layers < 2:\n",
    "\t\t\traise ValueError(\"n_hidden_layers must be greater than 1\")\n",
    "\t\t# Input layer\n",
    "\t\tlayers = [\n",
    "\t\t\tnn.Linear(input_dim, 200),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=dropout),\n",
    "\t\t]\n",
    "\t\t# Hidden layers\n",
    "\t\tlayers.extend([\n",
    "\t\t\tnn.Linear(200, 500),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=dropout)\n",
    "\t\t])\n",
    "\t\tfor _ in range(n_hidden_layers-2):\n",
    "\t\t\tlayers.extend([\n",
    "\t\t\t\tnn.Linear(500, 500),\n",
    "\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\tnn.Dropout(p=dropout)\n",
    "\t\t\t])\n",
    "\t\tlayers.extend([\n",
    "\t\t\tnn.Linear(500, 200),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=dropout)\n",
    "\t\t])\n",
    "\t\t# Output layer\n",
    "\t\tlayers.append(nn.Linear(200, 2))\n",
    "\t\tself.model = nn.Sequential(*layers)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\tparams = self.model(x)\n",
    "\t\tloc = params[:, 0:1]\n",
    "\t\tscale =  1e-6 + torch.nn.functional.softplus(0.33 * params[:, 1:2])\n",
    "\t\treturn torch.distributions.Normal(loc, scale)\n",
    "\t\n",
    "\tdef predict(self, X):\n",
    "\t\tself.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tpredictions = self(X).sample()\n",
    "\t\treturn predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_scaling_pyt(y, y_scaler, d=False):\n",
    "    if d:\n",
    "        return y_scaler.inverse_transform(y.detach().cpu().numpy().reshape(-1, 1))\n",
    "    return y_scaler.inverse_transform(y.cpu().numpy().reshape(-1, 1))\n",
    "\n",
    "def inv_scaling(y, y_scaler):\n",
    "    return y_scaler.inverse_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = '../models/'\n",
    "models_path = {\n",
    "\t'tabnet': models_folder + 'tabnet_model.zip',\n",
    "\t'mc_dropout': models_folder + 'mc_dropout_model.pt',\n",
    "\t'feedforward': models_folder + 'feedforward_model.pt',\n",
    "\t'xgboost': models_folder + 'xgboost_model.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, X, X_t, X_log, X_t_log, y_scaler, y_scaler_log):\n",
    "\tpredictions = []\n",
    "\tprediction = models[0].predict(X_t_log)\n",
    "\tpredictions.append(np.expm1(inv_scaling_pyt(prediction, y_scaler_log)))\n",
    "\tprediction = models[1].predict(X_t)\n",
    "\tpredictions.append(inv_scaling_pyt(prediction, y_scaler))\n",
    "\tprediction = models[2].predict(X_log)\n",
    "\tpredictions.append(np.expm1(inv_scaling(prediction, y_scaler_log)))\n",
    "\tprediction = models[3].predict(X)\n",
    "\tpredictions.append(inv_scaling(prediction, y_scaler))\n",
    "\tavg_predictions = np.mean(predictions, axis=0)\n",
    "\treturn avg_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frnk65/resource-prediction-study/venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# general models\n",
    "## TabNet\n",
    "tabnet = TabNetRegressor()\n",
    "tabnet.load_model(models_path['tabnet'])\n",
    "## XGBoost\n",
    "xgboost = xgb.XGBRegressor()\n",
    "xgboost.load_model(models_path['xgboost'])\n",
    "\n",
    "models = [\n",
    "    torch.load(models_path[\"feedforward\"]).to(DEVICE),\n",
    "    torch.load(models_path[\"mc_dropout\"]).to(DEVICE),\n",
    "    tabnet,\n",
    "    xgboost\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Val loss: 3.6627801875161023\n"
     ]
    }
   ],
   "source": [
    "preds = ensemble_predict(models, X_test, X_test_t, X_test_log, X_test_t_log, y_scaler, y_scaler_log)\n",
    "y_scaled = inv_scaling(y_test, y_scaler)\n",
    "rmse = np.sqrt(mean_squared_error(y_scaled, preds))\n",
    "print(f\"RMSE Val loss: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_val(model, X, X_t, X_log, X_t_log, y, y_scaler, y_scaler_log):\n",
    "\tmin_instance = {\"prediction\": float('inf'), \"actual\": 0, \"index\": 0}\n",
    "\tmax_instance = {\"prediction\": 0, \"actual\": 0, \"index\": 0}\n",
    "\t\n",
    "\tpredictions = ensemble_predict(model, X, X_t, X_log, X_t_log, y_scaler, y_scaler_log)\n",
    "\ty_scaled = inv_scaling(y, y_scaler)\n",
    "\tindex_min = np.argmin(np.abs(predictions - y_scaled))\n",
    "\tmin_instance[\"prediction\"] = predictions[index_min].item()\n",
    "\tmin_instance[\"actual\"] = y_scaled[index_min].item()\n",
    "\tmin_instance[\"index\"] = index_min\n",
    "\tindex_max = np.argmax(np.abs(predictions - y_scaled))\n",
    "\tmax_instance[\"prediction\"] = predictions[index_max].item()\n",
    "\tmax_instance[\"actual\"] = y_scaled[index_max].item()\n",
    "\tmax_instance[\"index\"] = index_max\n",
    "\n",
    "\treturn min_instance, max_instance, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set single thread model\n",
      "Mean prediction: 23.23479461669922 | Std actual: 42.17317581176758\n",
      "Mean actual: 23.631032844733987 | Std actual: 41.60096829835196\n",
      "Mean Error: 1.576265782239755 | Std Error: 3.223901116720842\n",
      "---\n",
      "Min instance\n",
      "total_time                                                            11.73\n",
      "total_cpu_usage                                                        0.99\n",
      "max_ram_usage                                                     45.234375\n",
      "brand_raw                          Intel(R) Xeon(R) Gold 6130 CPU @ 2.10GHz\n",
      "vendor_id_raw                                                  GenuineIntel\n",
      "arch                                                                 X86_64\n",
      "count                                                                    32\n",
      "l2_cache_size                                                          32.0\n",
      "l3_cache_size                                                          22.0\n",
      "l2_cache_line_size                                                      256\n",
      "l2_cache_associativity                                                    6\n",
      "benchmark                                                         TSPrl1323\n",
      "ghz_actual_friendly                                                     3.7\n",
      "ghz_advertised_friendly                                                 2.1\n",
      "score                                                                  1880\n",
      "munmap                                                                    4\n",
      "mprotect                                                                  9\n",
      "stat                                                                      1\n",
      "rt_sigaction                                                              2\n",
      "rt_sigprocmask                                                            1\n",
      "openat                                                                    9\n",
      "set_robust_list                                                           1\n",
      "fstat                                                                     8\n",
      "mmap                                                                     43\n",
      "read                                                                     12\n",
      "futex                                                                     2\n",
      "set_tid_address                                                           1\n",
      "prlimit64                                                                 1\n",
      "brk                                                                     219\n",
      "close                                                                     9\n",
      "total_time_target                                                     12.88\n",
      "brand_raw_target                  Intel(R) Xeon(R) CPU E5-2643 v3 @ 3.40GHz\n",
      "l2_cache_size_target                                                    3.0\n",
      "l3_cache_size_target                                                   20.0\n",
      "l2_cache_line_size_target                                               256\n",
      "l2_cache_associativity_target                                             6\n",
      "ghz_advertised_friendly_target                                          3.4\n",
      "score_target                                                           2099\n",
      "rss                                                               43.995803\n",
      "vms                                                               70.724277\n",
      "shared                                                            14.109998\n",
      "text                                                               0.035156\n",
      "data                                                              30.745387\n",
      "Name: 791, dtype: object\n",
      "Min Prediction: 12.879870414733887 | Actual: 12.88 | Error: 0.00012958526611406285\n",
      "---\n",
      "Max instance\n",
      "total_time                                                           251.93\n",
      "total_cpu_usage                                                        0.99\n",
      "max_ram_usage                                                     60.851562\n",
      "brand_raw                         Intel(R) Xeon(R) CPU E5-2643 v3 @ 3.40GHz\n",
      "vendor_id_raw                                                  GenuineIntel\n",
      "arch                                                                 X86_64\n",
      "count                                                                    12\n",
      "l2_cache_size                                                           3.0\n",
      "l3_cache_size                                                          20.0\n",
      "l2_cache_line_size                                                      256\n",
      "l2_cache_associativity                                                    6\n",
      "benchmark                                                   MATRIX_MULT_ST6\n",
      "ghz_actual_friendly                                                     3.7\n",
      "ghz_advertised_friendly                                                 3.4\n",
      "score                                                                  2099\n",
      "munmap                                                                    1\n",
      "mprotect                                                                  6\n",
      "stat                                                                      2\n",
      "rt_sigaction                                                              0\n",
      "rt_sigprocmask                                                            0\n",
      "openat                                                                    5\n",
      "set_robust_list                                                           0\n",
      "fstat                                                                     5\n",
      "mmap                                                                     22\n",
      "read                                                                      4\n",
      "futex                                                                     0\n",
      "set_tid_address                                                           0\n",
      "prlimit64                                                                 0\n",
      "brk                                                                     459\n",
      "close                                                                     5\n",
      "total_time_target                                                    180.85\n",
      "brand_raw_target                  Intel(R) Xeon(R) CPU E5-2670 v3 @ 2.30GHz\n",
      "l2_cache_size_target                                                    6.0\n",
      "l3_cache_size_target                                                   30.0\n",
      "l2_cache_line_size_target                                               256\n",
      "l2_cache_associativity_target                                             6\n",
      "ghz_advertised_friendly_target                                          2.3\n",
      "score_target                                                           1702\n",
      "rss                                                               60.297801\n",
      "vms                                                               63.057909\n",
      "shared                                                              2.58634\n",
      "text                                                               0.011719\n",
      "data                                                              57.956588\n",
      "Name: 4557, dtype: object\n",
      "Max Prediction: 222.11402893066406 | Actual: 180.85 | Error: 41.26402893066407\n"
     ]
    }
   ],
   "source": [
    "# single thread model\n",
    "print(\"Validation set single thread model\")\n",
    "min_instance, max_instance, predictions = describe_val(models, X_test, X_test_t, X_test_log, X_test_t_log, y_test, y_scaler, y_scaler_log)\n",
    "y_scaled = inv_scaling(y_test, y_scaler)\n",
    "errors = np.abs(predictions - y_scaled)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_scaled)} | Std actual: {np.std(y_scaled)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"---\")\n",
    "print(\"Min instance\")\n",
    "print(test_df.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(test_df.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
