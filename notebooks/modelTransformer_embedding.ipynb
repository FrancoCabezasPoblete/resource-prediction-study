{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "#from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if DEVICE.type == 'cuda':\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "sampler = TPESampler(seed=seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_to_MiB(row):\n",
    "\t# verify if has string ' MiB'\n",
    "\tif 'MiB' in str(row):\n",
    "\t\trow = row.replace(' MiB', '')\n",
    "\t\trow = float(row)\n",
    "\telse:\n",
    "\t\trow = float(row) / np.power(2, 20)\n",
    "\treturn row\n",
    "\n",
    "\n",
    "def MHz_to_GHz(row):\n",
    "\t# verify if has string ' GHz'\n",
    "\tif 'GHz' in str(row):\n",
    "\t\trow = row.replace(' GHz', '')\n",
    "\t\t# convert to float\n",
    "\t\trow = float(row)\n",
    "\telse:\n",
    "\t\trow = row.replace(' MHz', '')\n",
    "\t\trow = float(row) / 1000\n",
    "\treturn row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('../results_new/execution_time.csv')\n",
    "results_savio_df = pd.read_csv('../results_savio_new/execution_time.csv')\n",
    "results_df = pd.concat([results_df, results_savio_df], ignore_index=True)\n",
    "# preprocessing\n",
    "results_df['total_cpu_usage'] = results_df['total_cpu_usage'].str.replace('%', '').astype(float) / 100\n",
    "results_df['max_ram_usage'] = results_df['max_ram_usage'] / 1024\n",
    "results_df['l2_cache_size'] = results_df['l2_cache_size'].apply(bits_to_MiB)\n",
    "results_df['l3_cache_size'] = results_df['l3_cache_size'].apply(bits_to_MiB)\n",
    "results_df['ghz_actual_friendly'] = results_df['hz_actual_friendly'].apply(MHz_to_GHz)\n",
    "results_df['ghz_advertised_friendly'] = results_df['hz_advertised_friendly'].str.replace('GHz', '').astype(float)\n",
    "results_df = results_df.drop(columns=['hz_actual_friendly', 'hz_advertised_friendly', 'arch', 'vendor_id_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "      <th>total_cpu_usage</th>\n",
       "      <th>max_ram_usage</th>\n",
       "      <th>brand_raw</th>\n",
       "      <th>count</th>\n",
       "      <th>l2_cache_size</th>\n",
       "      <th>l3_cache_size</th>\n",
       "      <th>l2_cache_line_size</th>\n",
       "      <th>l2_cache_associativity</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>ghz_actual_friendly</th>\n",
       "      <th>ghz_advertised_friendly</th>\n",
       "      <th>total_time_target</th>\n",
       "      <th>brand_raw_target</th>\n",
       "      <th>count_target</th>\n",
       "      <th>l2_cache_size_target</th>\n",
       "      <th>l3_cache_size_target</th>\n",
       "      <th>l2_cache_line_size_target</th>\n",
       "      <th>l2_cache_associativity_target</th>\n",
       "      <th>ghz_advertised_friendly_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1436.714844</td>\n",
       "      <td>Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>KNP</td>\n",
       "      <td>4.1729</td>\n",
       "      <td>2.9</td>\n",
       "      <td>45.91</td>\n",
       "      <td>13th Gen Intel(R) Core(TM) i5-1335U</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>7</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1436.714844</td>\n",
       "      <td>Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>KNP</td>\n",
       "      <td>4.1729</td>\n",
       "      <td>2.9</td>\n",
       "      <td>25.77</td>\n",
       "      <td>13th Gen Intel(R) Core(TM) i5-1335U</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>7</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_time  total_cpu_usage  max_ram_usage  \\\n",
       "5       13.47             0.99    1436.714844   \n",
       "6       13.47             0.99    1436.714844   \n",
       "\n",
       "                                  brand_raw  count  l2_cache_size  \\\n",
       "5  Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz     12            1.5   \n",
       "6  Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz     12            1.5   \n",
       "\n",
       "   l3_cache_size  l2_cache_line_size  l2_cache_associativity benchmark  \\\n",
       "5           12.0                 256                       6       KNP   \n",
       "6           12.0                 256                       6       KNP   \n",
       "\n",
       "   ghz_actual_friendly  ghz_advertised_friendly  total_time_target  \\\n",
       "5               4.1729                      2.9              45.91   \n",
       "6               4.1729                      2.9              25.77   \n",
       "\n",
       "                      brand_raw_target  count_target  l2_cache_size_target  \\\n",
       "5  13th Gen Intel(R) Core(TM) i5-1335U            12                   7.5   \n",
       "6  13th Gen Intel(R) Core(TM) i5-1335U            12                   7.5   \n",
       "\n",
       "   l3_cache_size_target  l2_cache_line_size_target  \\\n",
       "5                  12.0                       1280   \n",
       "6                  12.0                       1280   \n",
       "\n",
       "   l2_cache_associativity_target  ghz_advertised_friendly_target  \n",
       "5                              7                           2.496  \n",
       "6                              7                           2.496  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the target dataset\n",
    "target_df = results_df[['total_time', 'brand_raw', 'count', 'l2_cache_size', 'l3_cache_size', 'l2_cache_line_size', 'l2_cache_associativity', 'ghz_advertised_friendly', 'benchmark']].copy()\n",
    "# Rename columns to *_target\n",
    "target_df = target_df.rename(columns={\n",
    "    'total_time': 'total_time_target',\n",
    "    'brand_raw': 'brand_raw_target',\n",
    "    'count': 'count_target',\n",
    "    'l2_cache_size': 'l2_cache_size_target',\n",
    "    'l3_cache_size': 'l3_cache_size_target',\n",
    "    'l2_cache_line_size': 'l2_cache_line_size_target',\n",
    "    'l2_cache_associativity': 'l2_cache_associativity_target',\n",
    "    'ghz_advertised_friendly': 'ghz_advertised_friendly_target',\n",
    "})\n",
    "\n",
    "dataset_df = pd.merge(results_df, target_df, how='inner', on='benchmark')\n",
    "dataset_df = dataset_df[dataset_df['brand_raw'] != dataset_df['brand_raw_target']]\n",
    "dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df = dataset_df[~dataset_df['benchmark'].isin(['MATRIX_MULT', 'MATRIX_MULT2', 'MATRIX_MULT3'])]\n",
    "# remove one computer for testing\n",
    "st_train = st_df[(st_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (st_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "st_test = st_df[st_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "# g_test = pd.read_csv('csv/g_test.csv')\n",
    "# st_test = pd.read_csv('csv/st_test.csv')\n",
    "# mm_test = pd.read_csv('csv/mm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'total_time_target'\n",
    "features = st_test.columns.copy().drop(target).drop(['benchmark','brand_raw', 'brand_raw_target'])\n",
    "embeddings = ['benchmark'] \n",
    "features_st = features.copy().drop(['count', 'count_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single thread data\n",
    "## split data\n",
    "X_st_train = st_train[features_st]\n",
    "y_st_train = st_train[target]\n",
    "emb_st_train = st_train[embeddings]\n",
    "\n",
    "X_st_test = st_test[features_st]\n",
    "y_st_test = st_test[target]\n",
    "emb_st_test = st_test[embeddings]\n",
    "\n",
    "## normalize data\n",
    "x_st_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_st_train = x_st_scaler.fit_transform(X_st_train)\n",
    "X_st_test = x_st_scaler.transform(X_st_test)\n",
    "y_st_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_st_train = y_st_scaler.fit_transform(y_st_train.values.reshape(-1, 1))\n",
    "y_st_test = y_st_scaler.transform(y_st_test.values.reshape(-1, 1))\n",
    "\n",
    "## convert to tensor\n",
    "X_st_train = torch.tensor(X_st_train, dtype=torch.float32)\n",
    "X_st_test = torch.tensor(X_st_test, dtype=torch.float32)\n",
    "y_st_train = torch.tensor(y_st_train, dtype=torch.float32)\n",
    "y_st_test = torch.tensor(y_st_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process embeddings\n",
    "import os\n",
    "benchmarks = emb_st_train['benchmark'].unique().copy()\n",
    "filenames = [f'strace_{x}.txt' for x in benchmarks]\n",
    "\n",
    "file_contents = []\n",
    "for filename in filenames:\n",
    "\twith open(os.path.join('..','results_new','X86_64', filename), 'r') as f:\n",
    "\t\tlines = f.readlines()\n",
    "\t\tfile_contents.append([line.strip() for line in lines])\n",
    "\n",
    "# process only syscalls\n",
    "list_of_sequences = []\n",
    "for file in file_contents:\n",
    "\tcalls = []\n",
    "\tfor line in file:\n",
    "\t\tif \"+++ exited with 0 +++\" in line:\n",
    "\t\t\tbreak\n",
    "\t\tcalls.append(line.split('(')[0])\n",
    "\tlist_of_sequences.append(calls)\n",
    "\n",
    "all_calls = [call for seq in list_of_sequences for call in seq]\n",
    "\n",
    "# mapping from calls to tokens\n",
    "call_to_token = {call: idx for idx, call in enumerate(set(all_calls))}\n",
    "token_to_call = {idx: call for call, idx in call_to_token.items()}\n",
    "\n",
    "# tokenize the sequences\n",
    "tokenized_sequences = [[call_to_token[call] for call in seq] for seq in list_of_sequences]\n",
    "\n",
    "# turn the tokenized sequences into tensors with padding\n",
    "sequences_tensors = [torch.tensor(seq) for seq in tokenized_sequences]\n",
    "padded_sequences = pad_sequence(sequences_tensors, batch_first=True, padding_value=0)\n",
    "\n",
    "# dict of benchmark to padded sequence\n",
    "benchmark_to_sequence = {bench: seq for bench, seq in zip(benchmarks, padded_sequences)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE.type == 'cuda':\n",
    "\t# move to DEVICE\n",
    "\tX_st_train = X_st_train.to(DEVICE)\n",
    "\ty_st_train = y_st_train.to(DEVICE)\n",
    "\tX_st_test = X_st_test.to(DEVICE)\n",
    "\ty_st_test = y_st_test.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_scaling(y, y_scaler, d=False):\n",
    "    if d:\n",
    "        return y_scaler.inverse_transform(y.detach().cpu().numpy().reshape(-1, 1))\n",
    "    return y_scaler.inverse_transform(y.cpu().numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\tdef __init__(self, input_dim_numeric, embedding_dim, seq_length, num_heads, num_layers, output_dim):\n",
    "\t\tsuper(TransformerModel, self).__init__()\n",
    "\t\t# layers\n",
    "\t\tself.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\t\tself.fc_numeric = nn.Linear(input_dim_numeric, embedding_dim)\n",
    "\t\tself.fc_final = nn.Linear(embedding_dim * (seq_length + 1), output_dim)\n",
    "\t\n",
    "\tdef forward(self, numeric_inputs, seq_inputs):\n",
    "\t\tnumeric_embeddings = self.fc_numeric(numeric_inputs)\n",
    "\t\tseq_embeddings = self.transformer_encoder(seq_inputs)\n",
    "\t\tcombined = torch.cat((seq_embeddings.flatten(1), numeric_embeddings), dim=1)\n",
    "\t\toutput = self.fc_final(combined)\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial, X_train, X_emb_train, y_train, X_test, y_test, input_num_dim, input_emb_dim, output_dim):\n",
    "\t# Definimos los hiperparámetros a buscar\n",
    "\tnum_heads = trial.suggest_int('num_heads', 1, 8)\n",
    "\tnum_layers = trial.suggest_int('num_layers', 1, 6)\n",
    "\tlearning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "\tweight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-2, log=True)\n",
    "\tnum_epochs = trial.suggest_int('num_epochs', 10, 100)\n",
    "\n",
    "\t# model initialization \n",
    "\tmodel = TransformerModel(input_num_dim, input_emb_dim, 5000, num_heads, num_layers, output_dim)\n",
    "\tif DEVICE.type == 'cuda':\n",
    "\t\tmodel = model.to(DEVICE)\n",
    "\tcriterion = nn.MSELoss()\n",
    "\toptimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\t# training\n",
    "\tmodel.train()\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutput = model(X_train)\n",
    "\t\tloss = criterion(output, y_train)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t# evaluation\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tpredictions = model(X_test)\n",
    "\t\tval_loss = criterion(predictions, y_test)\n",
    "\n",
    "\t\t# trial.report(val_loss.item(), epoch+1)\n",
    "\t\t# if trial.should_prune():\n",
    "\t\t# \traise optuna.TrialPruned()\n",
    "\tprint(f\"Trial: {trial.number} - Loss: {loss.item()} - Val Loss: {val_loss.item()}\")\n",
    "\treturn val_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 25\n",
    "study_st = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:55:24,799] A new study created in memory with name: no-name-dc29c454-4add-4623-b461-8651c59556d0\n",
      "[I 2024-07-03 07:55:34,940] Trial 0 finished with value: 62.06943893432617 and parameters: {'num_heads': 7, 'model_dim': 112, 'num_layers': 1, 'dropout': 0.42618457138193366, 'learning_rate': 0.001319994226153501, 'weight_decay': 0.0015382308040279, 'num_epochs': 80}. Best is trial 0 with value: 62.06943893432617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 - Loss: 307.4320068359375 - Val Loss: 62.06943893432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:55:35,386] Trial 1 finished with value: 507.5620422363281 and parameters: {'num_heads': 1, 'model_dim': 25, 'num_layers': 1, 'dropout': 0.4452413703502375, 'learning_rate': 0.0007411299781083245, 'weight_decay': 9.833181933644887e-05, 'num_epochs': 15}. Best is trial 0 with value: 62.06943893432617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1 - Loss: 744.2530517578125 - Val Loss: 507.5620422363281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:55:41,791] Trial 2 finished with value: 220.41946411132812 and parameters: {'num_heads': 3, 'model_dim': 69, 'num_layers': 5, 'dropout': 0.35502298854208525, 'learning_rate': 0.0045881565491609705, 'weight_decay': 0.00026100256506134784, 'num_epochs': 20}. Best is trial 0 with value: 62.06943893432617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 2 - Loss: 473.9880676269531 - Val Loss: 220.41946411132812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:56:09,826] Trial 3 finished with value: 145.89273071289062 and parameters: {'num_heads': 6, 'model_dim': 300, 'num_layers': 4, 'dropout': 0.40838687198182444, 'learning_rate': 0.00030296104428212476, 'weight_decay': 0.0003699972431463808, 'num_epochs': 48}. Best is trial 0 with value: 62.06943893432617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 3 - Loss: 389.7847900390625 - Val Loss: 145.89273071289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:56:12,314] Trial 4 finished with value: 542.7485961914062 and parameters: {'num_heads': 1, 'model_dim': 10, 'num_layers': 1, 'dropout': 0.3545641645055122, 'learning_rate': 8.771380343280557e-05, 'weight_decay': 0.0003355151022721483, 'num_epochs': 92}. Best is trial 0 with value: 62.06943893432617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 4 - Loss: 775.09228515625 - Val Loss: 542.7485961914062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:56:17,938] Trial 5 finished with value: 556.658447265625 and parameters: {'num_heads': 2, 'model_dim': 58, 'num_layers': 5, 'dropout': 0.191519266196649, 'learning_rate': 1.7019223026554023e-05, 'weight_decay': 7.40038575908737e-05, 'num_epochs': 24}. Best is trial 0 with value: 62.06943893432617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 5 - Loss: 775.6277465820312 - Val Loss: 556.658447265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:57:30,330] Trial 6 finished with value: 37.884891510009766 and parameters: {'num_heads': 8, 'model_dim': 424, 'num_layers': 4, 'dropout': 0.44858423607508713, 'learning_rate': 0.0025764174425233167, 'weight_decay': 3.6283583803549155e-05, 'num_epochs': 91}. Best is trial 6 with value: 37.884891510009766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 6 - Loss: 281.2131042480469 - Val Loss: 37.884891510009766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:58:06,843] Trial 7 finished with value: 283.6199035644531 and parameters: {'num_heads': 5, 'model_dim': 265, 'num_layers': 6, 'dropout': 0.22720138998874556, 'learning_rate': 2.1387290754148914e-05, 'weight_decay': 4.8284249748183215e-05, 'num_epochs': 48}. Best is trial 6 with value: 37.884891510009766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 7 - Loss: 524.4100952148438 - Val Loss: 283.6199035644531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:58:10,406] Trial 8 finished with value: 213.32315063476562 and parameters: {'num_heads': 7, 'model_dim': 392, 'num_layers': 1, 'dropout': 0.3042989210310263, 'learning_rate': 0.000178744632562384, 'weight_decay': 4.6379219034580266e-05, 'num_epochs': 20}. Best is trial 6 with value: 37.884891510009766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 8 - Loss: 443.738037109375 - Val Loss: 213.32315063476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:58:25,810] Trial 9 finished with value: 135.2371826171875 and parameters: {'num_heads': 3, 'model_dim': 183, 'num_layers': 2, 'dropout': 0.30751624869734645, 'learning_rate': 0.0012854549964879019, 'weight_decay': 0.00012327891605450807, 'num_epochs': 98}. Best is trial 6 with value: 37.884891510009766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 9 - Loss: 214.21823120117188 - Val Loss: 135.2371826171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:59:10,231] Trial 10 finished with value: 38.05074691772461 and parameters: {'num_heads': 8, 'model_dim': 496, 'num_layers': 3, 'dropout': 0.1246026171282115, 'learning_rate': 0.008106149171392763, 'weight_decay': 1.5025399484753894e-05, 'num_epochs': 69}. Best is trial 6 with value: 37.884891510009766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 10 - Loss: 281.2942810058594 - Val Loss: 38.05074691772461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 07:59:55,966] Trial 11 finished with value: 37.85926055908203 and parameters: {'num_heads': 8, 'model_dim': 512, 'num_layers': 3, 'dropout': 0.10589171034877662, 'learning_rate': 0.008149658576652717, 'weight_decay': 1.219583825009273e-05, 'num_epochs': 71}. Best is trial 11 with value: 37.85926055908203.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 11 - Loss: 281.20562744140625 - Val Loss: 37.85926055908203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:00:39,940] Trial 12 finished with value: 37.77417755126953 and parameters: {'num_heads': 8, 'model_dim': 512, 'num_layers': 3, 'dropout': 0.49215709557858045, 'learning_rate': 0.0028372961333157348, 'weight_decay': 1.0411236616031968e-05, 'num_epochs': 68}. Best is trial 12 with value: 37.77417755126953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 12 - Loss: 281.2080078125 - Val Loss: 37.77417755126953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:01:11,177] Trial 13 finished with value: 38.269779205322266 and parameters: {'num_heads': 6, 'model_dim': 384, 'num_layers': 3, 'dropout': 0.49664022433141086, 'learning_rate': 0.009186367110957461, 'weight_decay': 1.0863509237016974e-05, 'num_epochs': 66}. Best is trial 12 with value: 37.77417755126953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 13 - Loss: 281.20819091796875 - Val Loss: 38.269779205322266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:01:49,971] Trial 14 finished with value: 37.89213180541992 and parameters: {'num_heads': 8, 'model_dim': 512, 'num_layers': 3, 'dropout': 0.10368763693190514, 'learning_rate': 0.0031940106049038897, 'weight_decay': 0.004586798164817242, 'num_epochs': 61}. Best is trial 12 with value: 37.77417755126953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 14 - Loss: 281.1505126953125 - Val Loss: 37.89213180541992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:02:06,212] Trial 15 finished with value: 82.97280883789062 and parameters: {'num_heads': 5, 'model_dim': 190, 'num_layers': 2, 'dropout': 0.22973592976265728, 'learning_rate': 0.000676201440378111, 'weight_decay': 1.979748529126409e-05, 'num_epochs': 75}. Best is trial 12 with value: 37.77417755126953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 15 - Loss: 327.6230163574219 - Val Loss: 82.97280883789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:02:18,656] Trial 16 finished with value: 38.07381057739258 and parameters: {'num_heads': 7, 'model_dim': 336, 'num_layers': 2, 'dropout': 0.16322619687285683, 'learning_rate': 0.004210179973374917, 'weight_decay': 2.432317943590038e-05, 'num_epochs': 38}. Best is trial 12 with value: 37.77417755126953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 16 - Loss: 281.3700866699219 - Val Loss: 38.07381057739258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:03:01,583] Trial 17 finished with value: 37.23849105834961 and parameters: {'num_heads': 6, 'model_dim': 252, 'num_layers': 4, 'dropout': 0.2504274959984424, 'learning_rate': 0.0016940390315482881, 'weight_decay': 0.001067356851619411, 'num_epochs': 81}. Best is trial 17 with value: 37.23849105834961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 17 - Loss: 281.1636047363281 - Val Loss: 37.23849105834961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:03:56,976] Trial 18 finished with value: 37.26271438598633 and parameters: {'num_heads': 6, 'model_dim': 240, 'num_layers': 5, 'dropout': 0.2657724769815869, 'learning_rate': 0.0017536399739157401, 'weight_decay': 0.0011021199598813852, 'num_epochs': 87}. Best is trial 17 with value: 37.23849105834961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 18 - Loss: 281.17974853515625 - Val Loss: 37.26271438598633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:04:42,014] Trial 19 finished with value: 284.8900146484375 and parameters: {'num_heads': 4, 'model_dim': 184, 'num_layers': 6, 'dropout': 0.266075759280839, 'learning_rate': 5.985229427655942e-05, 'weight_decay': 0.0014194080627116961, 'num_epochs': 83}. Best is trial 17 with value: 37.23849105834961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 19 - Loss: 524.3458862304688 - Val Loss: 284.8900146484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:05:37,810] Trial 20 finished with value: 64.01228332519531 and parameters: {'num_heads': 6, 'model_dim': 240, 'num_layers': 5, 'dropout': 0.25891169456684265, 'learning_rate': 0.0005319533783152769, 'weight_decay': 0.0011210735795237944, 'num_epochs': 88}. Best is trial 17 with value: 37.23849105834961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 20 - Loss: 307.80596923828125 - Val Loss: 64.01228332519531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:06:09,473] Trial 21 finished with value: 38.89128494262695 and parameters: {'num_heads': 5, 'model_dim': 135, 'num_layers': 4, 'dropout': 0.3426511953937996, 'learning_rate': 0.0016169762892262577, 'weight_decay': 0.00392312460813385, 'num_epochs': 78}. Best is trial 17 with value: 37.23849105834961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 21 - Loss: 282.9061279296875 - Val Loss: 38.89128494262695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:07:12,749] Trial 22 finished with value: 37.341793060302734 and parameters: {'num_heads': 6, 'model_dim': 228, 'num_layers': 5, 'dropout': 0.2653976842275822, 'learning_rate': 0.0020999084932467383, 'weight_decay': 0.00988213445390245, 'num_epochs': 100}. Best is trial 17 with value: 37.23849105834961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 22 - Loss: 281.1385192871094 - Val Loss: 37.341793060302734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:08:15,549] Trial 23 finished with value: 105.7842025756836 and parameters: {'num_heads': 6, 'model_dim': 234, 'num_layers': 5, 'dropout': 0.2691750909442026, 'learning_rate': 0.0003436782144940018, 'weight_decay': 0.007187818462626211, 'num_epochs': 98}. Best is trial 17 with value: 37.23849105834961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 23 - Loss: 348.4277648925781 - Val Loss: 105.7842025756836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 08:09:12,858] Trial 24 finished with value: 37.23106002807617 and parameters: {'num_heads': 4, 'model_dim': 212, 'num_layers': 6, 'dropout': 0.19657967657361075, 'learning_rate': 0.0015831434455046685, 'weight_decay': 0.0007568934817355099, 'num_epochs': 100}. Best is trial 24 with value: 37.23106002807617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 24 - Loss: 281.19830322265625 - Val Loss: 37.23106002807617\n"
     ]
    }
   ],
   "source": [
    "# configuration optuna\n",
    "study_st = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "study_st.optimize(lambda trial: objective(trial, X_st_train, y_st_train, X_st_test, y_st_test, len(features_st), 1), n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pruebas: 25\n",
      "Mejor prueba: 24\n",
      "Mejores parametros: {'num_heads': 4, 'model_dim': 212, 'num_layers': 6, 'dropout': 0.19657967657361075, 'learning_rate': 0.0015831434455046685, 'weight_decay': 0.0007568934817355099, 'num_epochs': 100}\n",
      "Mejor valor de pérdida en validación: 37.23106002807617\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(f'Número de pruebas: {len(study_st.trials)}')\n",
    "trial = study_st.best_trial\n",
    "print(f'Mejor prueba: {trial.number}')\n",
    "print(f'Mejores parametros: {trial.params}')\n",
    "print(f'Mejor valor de pérdida en validación: {trial.value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = '../models/transformer'\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(scaler_g, f'{models_folder}/scaler_g.joblib')\n",
    "#dump(scaler_st, f'{models_folder}/scaler_st.joblib')\n",
    "#dump(scaler_mm, f'{models_folder}/scaler_mm.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(features_st)\n",
    "# hyperparameters\n",
    "if study_st is not None:\n",
    "\tnum_heads = study_st.best_trial.params['num_heads']\n",
    "\tmodel_dim = study_st.best_trial.params['model_dim']\n",
    "\tnum_layers = study_st.best_trial.params['num_layers']\n",
    "\tdropout = study_st.best_trial.params['dropout']\n",
    "\tlr = study_st.best_trial.params['learning_rate']\n",
    "\twd = study_st.best_trial.params['weight_decay']\n",
    "\tnum_epochs = study_st.best_trial.params['num_epochs']\n",
    "else:\n",
    "\tnum_heads = 6\n",
    "\tmodel_dim = 192\n",
    "\tnum_layers = 4\n",
    "\tdropout = 0.3731512093597947\n",
    "\tlr = 0.0027591245533166004\n",
    "\twd = 0.0014100590768903643\n",
    "\tnum_epochs = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 468.1701965332031, Val Loss: 215.08013916015625\n",
      "Epoch 20/100, Loss: 387.3863220214844, Val Loss: 137.333984375\n",
      "Epoch 30/100, Loss: 329.1274719238281, Val Loss: 81.00090026855469\n",
      "Epoch 40/100, Loss: 295.8929138183594, Val Loss: 49.859031677246094\n",
      "Epoch 50/100, Loss: 283.1757507324219, Val Loss: 38.61391067504883\n",
      "Epoch 60/100, Loss: 281.1542053222656, Val Loss: 37.20664596557617\n",
      "Epoch 70/100, Loss: 281.47821044921875, Val Loss: 37.50769805908203\n",
      "Epoch 80/100, Loss: 281.2610778808594, Val Loss: 37.17526626586914\n",
      "Epoch 90/100, Loss: 281.125244140625, Val Loss: 37.208595275878906\n",
      "Epoch 100/100, Loss: 281.1525573730469, Val Loss: 37.19477844238281\n"
     ]
    }
   ],
   "source": [
    "# single thread model initialization\n",
    "model_st = TransformerModel(input_dim, model_dim, num_heads, num_layers, output_dim, dropout)\n",
    "if DEVICE.type == 'cuda':\n",
    "\tmodel_st = model_st.to(DEVICE)\n",
    "criterion_st = nn.MSELoss()\n",
    "optimizer_st = optim.AdamW(model_st.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "model_st.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\toptimizer_st.zero_grad()\n",
    "\toutput = model_st(X_st_train)\n",
    "\tloss = criterion_st(output, y_st_train)\n",
    "\tloss.backward()\n",
    "\toptimizer_st.step()\n",
    "\t# validation\n",
    "\tif (epoch+1) % 10 == 0 or epoch == num_epochs-1:\n",
    "\t\tmodel_st.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tval_predictions = model_st(X_st_test)\n",
    "\t\t\tval_loss = criterion_st(val_predictions, y_st_test)\n",
    "\t\tprint(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}')\n",
    "\t\tmodel_st.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 37.19477844238281 - RMSE: 6.098752021789551 - MAE: 3.26633358001709\n"
     ]
    }
   ],
   "source": [
    "model_st.eval()\n",
    "with torch.no_grad():\n",
    "\tpreds = model_st(X_st_test).cpu().numpy().flatten()\n",
    "mse = mean_squared_error(y_st_test.cpu().numpy().flatten(), preds)\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mean_absolute_error(y_st_test.cpu().numpy().flatten(), preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model_st, f'{models_folder}/single_thread.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_st = torch.load(f'{models_folder}/single_thread.pt').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 instance prediction\n",
    "def predict(model, X):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tprediction = model(X)\n",
    "\treturn prediction\n",
    "\n",
    "def describe_val(model, X, y):\n",
    "\tmin_instance = {\"prediction\": float('inf'), \"actual\": 0, \"index\": 0}\n",
    "\tmax_instance = {\"prediction\": 0, \"actual\": 0, \"index\": 0}\n",
    "\t\n",
    "\tpredictions = predict(model, X).cpu().numpy().flatten()\n",
    "\tindex_min = np.argmin(np.abs(predictions - y.cpu().numpy().flatten()))\n",
    "\tmin_instance[\"prediction\"] = predictions[index_min]\n",
    "\tmin_instance[\"actual\"] = y.cpu().numpy().flatten()[index_min]\n",
    "\tmin_instance[\"index\"] = index_min\n",
    "\tindex_max = np.argmax(np.abs(predictions - y.cpu().numpy().flatten()))\n",
    "\tmax_instance[\"prediction\"] = predictions[index_max]\n",
    "\tmax_instance[\"actual\"] = y.cpu().numpy().flatten()[index_max]\n",
    "\tmax_instance[\"index\"] = index_max\n",
    "\n",
    "\treturn min_instance, max_instance, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set single thread model\n",
      "Mean prediction: 24.714994430541992 | Std actual: 4.625657311407849e-06\n",
      "Mean actual: 24.564001083374023 | Std actual: 6.096883296966553\n",
      "Mean Error: 3.26633358001709 | Std Error: 5.150325298309326\n",
      "Min instance\n",
      "total_time                                                             24.7\n",
      "total_cpu_usage                                                        0.99\n",
      "max_ram_usage                                                     10.207031\n",
      "brand_raw                         Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz\n",
      "count                                                                     8\n",
      "l2_cache_size                                                           2.0\n",
      "l3_cache_size                                                          10.0\n",
      "l2_cache_line_size                                                      256\n",
      "l2_cache_associativity                                                    2\n",
      "benchmark                                                          N_Queens\n",
      "ghz_actual_friendly                                                     3.0\n",
      "ghz_advertised_friendly                                                 3.0\n",
      "total_time_target                                                     24.81\n",
      "brand_raw_target                        13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                             12\n",
      "l2_cache_size_target                                                    7.5\n",
      "l3_cache_size_target                                                   12.0\n",
      "l2_cache_line_size_target                                              1280\n",
      "l2_cache_associativity_target                                             7\n",
      "ghz_advertised_friendly_target                                        2.496\n",
      "Name: 476, dtype: object\n",
      "Min Prediction: 24.714998245239258 | Actual: 24.809999465942383 | Error: 0.095001220703125\n",
      "---\n",
      "Max instance\n",
      "total_time                                                       13.07\n",
      "total_cpu_usage                                                    1.0\n",
      "max_ram_usage                                              1436.878906\n",
      "brand_raw                         12th Gen Intel(R) Core(TM) i5-12400F\n",
      "count                                                               12\n",
      "l2_cache_size                                                      7.5\n",
      "l3_cache_size                                                     18.0\n",
      "l2_cache_line_size                                                1280\n",
      "l2_cache_associativity                                               7\n",
      "benchmark                                                          KNP\n",
      "ghz_actual_friendly                                              2.496\n",
      "ghz_advertised_friendly                                          2.496\n",
      "total_time_target                                                45.91\n",
      "brand_raw_target                   13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                        12\n",
      "l2_cache_size_target                                               7.5\n",
      "l3_cache_size_target                                              12.0\n",
      "l2_cache_line_size_target                                         1280\n",
      "l2_cache_associativity_target                                        7\n",
      "ghz_advertised_friendly_target                                   2.496\n",
      "Name: 165, dtype: object\n",
      "Max Prediction: 24.714984893798828 | Actual: 45.90999984741211 | Error: 21.19501495361328\n"
     ]
    }
   ],
   "source": [
    "# single thread model\n",
    "print(\"Validation set single thread model\")\n",
    "min_instance, max_instance, predictions = describe_val(model_st, X_st_test, y_st_test)\n",
    "errors = np.abs(predictions - y_st_test.cpu().numpy().flatten())\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_st_test.cpu().numpy().flatten())} | Std actual: {np.std(y_st_test.cpu().numpy().flatten())}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"Min instance\")\n",
    "print(st_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(st_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
