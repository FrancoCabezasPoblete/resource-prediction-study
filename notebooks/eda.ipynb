{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('../results/execution_time.csv')\n",
    "# preprocessing\n",
    "results_df['total_cpu_usage'] = results_df['total_cpu_usage'].str.replace('%', '').astype(float) / 100\n",
    "results_df['max_ram_usage'] = results_df['max_ram_usage'] / np.power(1024,2)\n",
    "results_df['l2_cache_size_mb'] = results_df['l2_cache_size'].str.replace(' MiB', '').astype(float)\n",
    "results_df['l3_cache_size_mb'] = results_df['l3_cache_size'] / np.power(1024,2)\n",
    "results_df['ghz_actual_friendly'] = results_df['hz_actual_friendly'].str.replace('GHz', '').astype(float)\n",
    "results_df['ghz_advertised_friendly'] = results_df['hz_advertised_friendly'].str.replace('GHz', '').astype(float)\n",
    "results_df = results_df.drop(columns=['hz_actual_friendly', 'hz_advertised_friendly','l2_cache_size','l3_cache_size','total_ram_gb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC's utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count = Threads\n",
    "results_df[['brand_raw','vendor_id_raw','arch','count']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication (5000x5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df = results_df[results_df['benchmark']=='matrix_multiplication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_memory_usage and swaps are not available for containerized benchmarks\n",
    "mm_df[['total_time','total_cpu_usage','total_memory_usage','max_ram_usage','swaps']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(mm_df, x='total_time', hue='brand_raw')\n",
    "plt.title('Histogram of Total Time')\n",
    "plt.xlabel('Total Time [s]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=mm_df, x='total_time', y='brand_raw')\n",
    "plt.title('Boxplot of Total Time')\n",
    "plt.xlabel('Total Time [s]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la distribución del tiempo de ejecución varia bastante dependiendo del procesador usado, una relación bastante trivial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(mm_df, x='max_ram_usage', hue='brand_raw')\n",
    "plt.title('Histogram of Max RAM Usage')\n",
    "plt.xlabel('Max RAM Usage [GB]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=mm_df, x='max_ram_usage', y='brand_raw')\n",
    "plt.title('Boxplot of Max RAM Usage')\n",
    "plt.xlabel('Max RAM Usage [GB]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la RAM maxima utilizada no cambia, esto debido a que la cantidad de memoria utilizada es inherente del programa, al menos en este benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se profundizara en las correlaciones entre las variables medidas en la ejecución y las características de los procesadores para poder entender los atributos que más influyen, en especifico se analizará en el tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = mm_df[['total_time', 'total_cpu_usage', 'max_ram_usage', 'l3_cache_size_mb', 'l2_cache_line_size', 'l2_cache_associativity','count','ghz_actual_friendly','ghz_advertised_friendly']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos puntos a tener en cuenta, con lo mostrado en el mapa de correlaciones:\n",
    "\n",
    "- **No linealidad**: La correlación entre las variables y el tiempo de ejecución no es lineal de manera general, por lo que un modelo lineal no sería suficiente para capturar la relación entre las variables y el tiempo de ejecución, como en los casos de alta correlación negativa entre `l2_cache_associativity` y `total_time` o alta correlación positiva entre `total_cpu_usage` y `total_time` u otras correlaciones moderadas que sugieren que las relaciones no son estrictamente lineales. Métodos como random forest pueden capturar relaciones no lineales hasta cierto punto, pero pueden volverse demasiado complejos o ineficientes.\n",
    "\n",
    "- **Multicolinealidad**:  La alta correlación entre variables independientes (como `total_cpu_usage` y `count` con un valor de 0.99), puede causar problemas en una regresión lineal. Esto puede hacer que las estimaciones sean inestables y difíciles de interpretar. Métodos tradicionales podrían requerir un preprocesamiento de las variables para manejar la multicolinealidad (como PCA), lo que añade complejidad al modelo y puede hacerlo menos interpretable.\n",
    "\n",
    "Aún con los datos obtenidos, muchos procesos computacionales son afectados por factores que pueden no estar directamente medidos o incluidos en el dataset, como variaciones en la carga de trabajo que no se capturan completamente con las variables disponibles, o algunos que se pudieran incluir a futuro como condiciones térmicas, voltaje o incluso las llamadas al sistema que ejecuta el programa.\n",
    "\n",
    "Las interacciones entre variables, como la combinación de tipo de arquitectura y tamaño de cache, pueden tener efectos importantes en el tiempo total que no son capturables mediante una simple regresión lineal.\n",
    "\n",
    "Para esto, los modelos de *deep learning* podrían ofrecer mejoras significativas en la predicción de `total_time` como la capacidad de manejar no linealidad, multicolinealidad, interacciones complejas y la posible incorporación de variables categóricas mediante embeddings, incluyendo las **llamadas al sistema** teniendo asi un mayor conocimiento sobre el comportamiento del programa, proporcionando así un modelo más robusto y preciso para predecir **total_time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuritas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ahora se procederá a realizar un análisis de componentes principales para reducir la dimensionalidad de los datos y poder visualizar mejor las relaciones entre las variables, además de poder identificar posibles grupos de variables que puedan ser usadas para modelar el tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(mm_df[\n",
    "    ['total_cpu_usage', 'max_ram_usage', 'l3_cache_size_mb', 'l2_cache_line_size', 'l2_cache_associativity','count','ghz_actual_friendly','ghz_advertised_friendly']\n",
    "])\n",
    "pca = PCA(n_components=0.99)  # 99% of varianze\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=[f\"PC{i+1}\" for i in range(principal_components.shape[1])])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.6, label='Individual explained variance')\n",
    "plt.step(range(1, len(explained_variance) + 1), np.cumsum(explained_variance), where='mid', color='magenta', label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f\"PC1: {explained_variance[0]} | PC2: {explained_variance[1]} | PC3: {explained_variance[2]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los componentes principales resultantes capturan:\n",
    "- **PC1**: 54.62% de la varianza total.\n",
    "- **PC2**: 33.9% de la varianza total.\n",
    "- **PC3**: 11.38% de la varianza total.\n",
    "\n",
    "Con estos tres primeros componentes, retenemos aproximadamente el 99% de la varianza total, por casi toda la información ha sido conservada al realizar la reducción.\n",
    "\n",
    "Ahora se visualizará la importancia de las variables en cada componente principal, para poder identificar las variables que más influyen en el tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.components_\n",
    "num_components = components.shape[0]\n",
    "features = ['total_cpu_usage', 'max_ram_usage', 'l3_cache_size_mb', 'l2_cache_line_size', 'l2_cache_associativity','count','ghz_actual_friendly','ghz_advertised_friendly']\n",
    "\n",
    "for i in range(num_components):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    component = components[i]\n",
    "    colors = ['red' if val < 0 else 'green' for val in component]\n",
    "    plt.barh(features, component, color=colors)\n",
    "    plt.ylabel('Weight')\n",
    "    plt.title(f'Weights PCA{i+1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pesos para cada componente principal nos dicen cómo contribuye cada variable original a ese componente:\n",
    "- Pesos positivos o negativos altos indican una fuerte influencia de la variable en ese componente.\n",
    "- Pesos cercanos a cero indican una baja influencia.\n",
    "Estos componentes principales pueden ser utilizados como entradas para los modelos predictivos de `total_time`.\n",
    "\n",
    "Notar que en el componente principal 3 la variable `max_ram_usage` destaca como la más importante, lo que sugiere que la cantidad de memoria utilizada es un factor importante en el tiempo de ejecución, al menos en aproximadamente un 11.38% de la varianza total. En los otros componentes principales, las variables tienen pesos más equilibrados, lo que sugiere que la influencia de las variables más equitativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knapsack problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knp_df = results_df[results_df['benchmark']=='KNP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knp_df[['total_time','total_cpu_usage','max_ram_usage']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(knp_df, x='total_time', hue='brand_raw')\n",
    "plt.title('Histogram of Total Time')\n",
    "plt.xlabel('Total Time (s)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=knp_df, x='total_time', y='brand_raw')\n",
    "plt.title('Boxplot of Total Time')\n",
    "plt.xlabel('Total Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical variables\n",
    "correlation_matrix = knp_df[['total_time', 'total_cpu_usage', 'max_ram_usage', 'l3_cache_size_mb', 'l2_cache_line_size', 'l2_cache_associativity','count','ghz_actual_friendly','ghz_advertised_friendly']].corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Queens problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_df = results_df[results_df['benchmark']=='N_Queens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_df[['total_time','total_cpu_usage','max_ram_usage']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(nq_df, x='total_time', hue='brand_raw')\n",
    "plt.title('Histogram of Total Time')\n",
    "plt.xlabel('Total Time (s)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=nq_df, x='total_time', y='brand_raw')\n",
    "plt.title('Boxplot of Total Time')\n",
    "plt.xlabel('Total Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical variables\n",
    "correlation_matrix = nq_df[['total_time', 'total_cpu_usage', 'max_ram_usage', 'l3_cache_size_mb', 'l2_cache_line_size', 'l2_cache_associativity','count','ghz_actual_friendly','ghz_advertised_friendly']].corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travelling Salesman problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_df = results_df[results_df['benchmark']=='N_Queens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_df[['total_time','total_cpu_usage','max_ram_usage']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(tsp_df, x='total_time', hue='brand_raw')\n",
    "plt.title('Histogram of Total Time')\n",
    "plt.xlabel('Total Time (s)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=tsp_df, x='total_time', y='brand_raw')\n",
    "plt.title('Boxplot of Total Time')\n",
    "plt.xlabel('Total Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical variables\n",
    "correlation_matrix = tsp_df[['total_time', 'total_cpu_usage', 'max_ram_usage', 'l3_cache_size_mb', 'l2_cache_line_size', 'l2_cache_associativity','count','ghz_actual_friendly','ghz_advertised_friendly']].corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
