{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "sampler = TPESampler(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_to_MiB(row):\n",
    "\t# verify if has string ' MiB'\n",
    "\tif 'MiB' in str(row):\n",
    "\t\trow = row.replace(' MiB', '')\n",
    "\t\trow = float(row)\n",
    "\telse:\n",
    "\t\trow = float(row) / np.power(2, 20)\n",
    "\treturn row\n",
    "\n",
    "\n",
    "def MHz_to_GHz(row):\n",
    "\t# verify if has string ' GHz'\n",
    "\tif 'GHz' in str(row):\n",
    "\t\trow = row.replace(' GHz', '')\n",
    "\t\t# convert to float\n",
    "\t\trow = float(row)\n",
    "\telse:\n",
    "\t\trow = row.replace(' MHz', '')\n",
    "\t\trow = float(row) / 1000\n",
    "\treturn row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('../results_new/execution_time.csv')\n",
    "results_savio_df = pd.read_csv('../results_savio_new/execution_time.csv')\n",
    "results_df = pd.concat([results_df, results_savio_df], ignore_index=True)\n",
    "# preprocessing\n",
    "results_df['total_cpu_usage'] = results_df['total_cpu_usage'].str.replace('%', '').astype(float) / 100\n",
    "results_df['max_ram_usage'] = results_df['max_ram_usage'] / 1024\n",
    "results_df['l2_cache_size'] = results_df['l2_cache_size'].apply(bits_to_MiB)\n",
    "results_df['l3_cache_size'] = results_df['l3_cache_size'].apply(bits_to_MiB)\n",
    "results_df['ghz_actual_friendly'] = results_df['hz_actual_friendly'].apply(MHz_to_GHz)\n",
    "results_df['ghz_advertised_friendly'] = results_df['hz_advertised_friendly'].str.replace('GHz', '').astype(float)\n",
    "results_df = results_df.drop(columns=['hz_actual_friendly', 'hz_advertised_friendly', 'arch', 'vendor_id_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "      <th>total_cpu_usage</th>\n",
       "      <th>max_ram_usage</th>\n",
       "      <th>brand_raw</th>\n",
       "      <th>count</th>\n",
       "      <th>l2_cache_size</th>\n",
       "      <th>l3_cache_size</th>\n",
       "      <th>l2_cache_line_size</th>\n",
       "      <th>l2_cache_associativity</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>ghz_actual_friendly</th>\n",
       "      <th>ghz_advertised_friendly</th>\n",
       "      <th>total_time_target</th>\n",
       "      <th>brand_raw_target</th>\n",
       "      <th>count_target</th>\n",
       "      <th>l2_cache_size_target</th>\n",
       "      <th>l3_cache_size_target</th>\n",
       "      <th>l2_cache_line_size_target</th>\n",
       "      <th>l2_cache_associativity_target</th>\n",
       "      <th>ghz_advertised_friendly_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1436.714844</td>\n",
       "      <td>Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>KNP</td>\n",
       "      <td>4.1729</td>\n",
       "      <td>2.9</td>\n",
       "      <td>45.91</td>\n",
       "      <td>13th Gen Intel(R) Core(TM) i5-1335U</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>7</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1436.714844</td>\n",
       "      <td>Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>KNP</td>\n",
       "      <td>4.1729</td>\n",
       "      <td>2.9</td>\n",
       "      <td>25.77</td>\n",
       "      <td>13th Gen Intel(R) Core(TM) i5-1335U</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>7</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_time  total_cpu_usage  max_ram_usage  \\\n",
       "5       13.47             0.99    1436.714844   \n",
       "6       13.47             0.99    1436.714844   \n",
       "\n",
       "                                  brand_raw  count  l2_cache_size  \\\n",
       "5  Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz     12            1.5   \n",
       "6  Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz     12            1.5   \n",
       "\n",
       "   l3_cache_size  l2_cache_line_size  l2_cache_associativity benchmark  \\\n",
       "5           12.0                 256                       6       KNP   \n",
       "6           12.0                 256                       6       KNP   \n",
       "\n",
       "   ghz_actual_friendly  ghz_advertised_friendly  total_time_target  \\\n",
       "5               4.1729                      2.9              45.91   \n",
       "6               4.1729                      2.9              25.77   \n",
       "\n",
       "                      brand_raw_target  count_target  l2_cache_size_target  \\\n",
       "5  13th Gen Intel(R) Core(TM) i5-1335U            12                   7.5   \n",
       "6  13th Gen Intel(R) Core(TM) i5-1335U            12                   7.5   \n",
       "\n",
       "   l3_cache_size_target  l2_cache_line_size_target  \\\n",
       "5                  12.0                       1280   \n",
       "6                  12.0                       1280   \n",
       "\n",
       "   l2_cache_associativity_target  ghz_advertised_friendly_target  \n",
       "5                              7                           2.496  \n",
       "6                              7                           2.496  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the target dataset\n",
    "target_df = results_df[['total_time', 'brand_raw', 'count', 'l2_cache_size', 'l3_cache_size', 'l2_cache_line_size', 'l2_cache_associativity', 'ghz_advertised_friendly', 'benchmark']].copy()\n",
    "# Rename columns to *_target\n",
    "target_df = target_df.rename(columns={\n",
    "    'total_time': 'total_time_target',\n",
    "    'brand_raw': 'brand_raw_target',\n",
    "    'count': 'count_target',\n",
    "    'l2_cache_size': 'l2_cache_size_target',\n",
    "    'l3_cache_size': 'l3_cache_size_target',\n",
    "    'l2_cache_line_size': 'l2_cache_line_size_target',\n",
    "    'l2_cache_associativity': 'l2_cache_associativity_target',\n",
    "    'ghz_advertised_friendly': 'ghz_advertised_friendly_target',\n",
    "})\n",
    "\n",
    "dataset_df = pd.merge(results_df, target_df, how='inner', on='benchmark')\n",
    "dataset_df = dataset_df[dataset_df['brand_raw'] != dataset_df['brand_raw_target']]\n",
    "dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove one computer for testing\n",
    "g_train = dataset_df[(dataset_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (dataset_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "g_test = dataset_df[dataset_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df = dataset_df[dataset_df['benchmark'].isin(['MATRIX_MULT', 'MATRIX_MULT2', 'MATRIX_MULT3'])]\n",
    "# remove one computer for testing\n",
    "mm_train = mm_df[(mm_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (mm_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "mm_test = mm_df[mm_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df = dataset_df[~dataset_df['benchmark'].isin(['MATRIX_MULT', 'MATRIX_MULT2', 'MATRIX_MULT3'])]\n",
    "# remove one computer for testing\n",
    "st_train = st_df[(st_df['brand_raw'] != '13th Gen Intel(R) Core(TM) i5-1335U') & (st_df['brand_raw_target'] != '13th Gen Intel(R) Core(TM) i5-1335U')]\n",
    "st_test = st_df[st_df['brand_raw_target'] == '13th Gen Intel(R) Core(TM) i5-1335U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "# g_test = pd.read_csv('csv/g_test.csv')\n",
    "# st_test = pd.read_csv('csv/st_test.csv')\n",
    "# mm_test = pd.read_csv('csv/mm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'total_time_target'\n",
    "features = mm_test.columns.copy().drop(target).drop(['benchmark','brand_raw', 'brand_raw_target'])\n",
    "features_st = features.copy().drop(['count', 'count_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general data\n",
    "## split data\n",
    "X_g_train = g_train[features]\n",
    "y_g_train = g_train[target]\n",
    "\n",
    "X_g_test = g_test[features]\n",
    "y_g_test = g_test[target]\n",
    "\n",
    "## normalize data\n",
    "x_g_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_g_train = x_g_scaler.fit_transform(X_g_train)\n",
    "X_g_test = x_g_scaler.transform(X_g_test)\n",
    "y_g_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_g_train = y_g_scaler.fit_transform(y_g_train.values.reshape(-1, 1)).flatten()\n",
    "y_g_test = y_g_scaler.transform(y_g_test.values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single thread data\n",
    "## split data\n",
    "X_st_train = st_train[features_st]\n",
    "y_st_train = st_train[target]\n",
    "\n",
    "X_st_test = st_test[features_st]\n",
    "y_st_test = st_test[target]\n",
    "\n",
    "## normalize data\n",
    "x_st_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_st_train = x_st_scaler.fit_transform(X_st_train)\n",
    "X_st_test = x_st_scaler.transform(X_st_test)\n",
    "y_st_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_st_train = y_st_scaler.fit_transform(y_st_train.values.reshape(-1, 1)).flatten()\n",
    "y_st_test = y_st_scaler.transform(y_st_test.values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi thread data\n",
    "## split data\n",
    "X_mm_train = mm_train[features]\n",
    "y_mm_train = mm_train[target]\n",
    "\n",
    "X_mm_test = mm_test[features]\n",
    "y_mm_test = mm_test[target]\n",
    "\n",
    "## normalize data\n",
    "x_mm_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_mm_train = x_mm_scaler.fit_transform(X_mm_train)\n",
    "X_mm_test = x_mm_scaler.transform(X_mm_test)\n",
    "y_mm_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_mm_train = y_mm_scaler.fit_transform(y_mm_train.values.reshape(-1, 1)).flatten()\n",
    "y_mm_test = y_mm_scaler.transform(y_mm_test.values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_scaling(y, y_scaler):\n",
    "    return y_scaler.inverse_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial, X_train, y_train, X_test, y_test, y_scaler):\n",
    "\tdtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\tdtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\t\n",
    "\t# Definimos los hiperparámetros a buscar (XGBoost)\n",
    "\tparam = {\n",
    "\t\t\"verbosity\": 0,\n",
    "\t\t\"device\": \"gpu\",\n",
    "\t\t\"objective\": \"reg:squarederror\",\n",
    "\t\t\"eval_metric\": \"rmse\",\n",
    "\t\t\"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "\t\t# L2 regularization weight.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # L1 regularization weight.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "\t\t\"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "\t}\n",
    "    \n",
    "\tif param[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "\t\t# maximum depth of the tree, signifies complexity of the tree.\n",
    "\t\tparam[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
    "\t\t# minimum child weight, larger the term more conservative the tree.\n",
    "\t\tparam[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "\t\tparam[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "\t\t# defines how selective algorithm is.\n",
    "\t\tparam[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "\t\tparam[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "\tif param[\"booster\"] == \"dart\":\n",
    "\t\tparam[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "\t\tparam[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "\t\tparam[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "\t\tparam[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "\t# training\n",
    "\tmodel = xgb.train(param, dtrain)\n",
    "\t# evaluation\n",
    "\tpreds = model.predict(dtest)\n",
    "\tmse_scaled = mean_squared_error(y_test, preds)\n",
    "\tmse = mean_squared_error(inv_scaling(y_test, y_scaler), inv_scaling(preds, y_scaler))\n",
    "\trmse = np.sqrt(mse)\n",
    "\tmae = mean_absolute_error(inv_scaling(y_test, y_scaler), inv_scaling(preds, y_scaler))\n",
    "\tprint(f\"Trial: {trial.number} - MSE: {mse} - RMSE: {rmse} - MAE: {mae}\")\n",
    "\treturn mse_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 100\n",
    "study_g = None\n",
    "study_st = None\n",
    "study_mm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 - MSE: 987.790185682391 - RMSE: 31.42912957245859 - MAE: 16.557445205853433\n",
      "Trial: 1 - MSE: 1001.4878772945153 - RMSE: 31.646293263106113 - MAE: 16.676376172452358\n",
      "Trial: 2 - MSE: 989.1930298208531 - RMSE: 31.451439232900825 - MAE: 16.56421613827267\n",
      "Trial: 3 - MSE: 993.30851145354 - RMSE: 31.516797290548734 - MAE: 16.602446835285907\n",
      "Trial: 4 - MSE: 996.4279226058027 - RMSE: 31.566246571390185 - MAE: 16.647650665901804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 5 - MSE: 993.9034794240918 - RMSE: 31.5262347803237 - MAE: 16.648870899922137\n",
      "Trial: 6 - MSE: 1001.4878772945153 - RMSE: 31.646293263106113 - MAE: 16.676376172452358\n",
      "Trial: 7 - MSE: 987.1253142210559 - RMSE: 31.418550479311676 - MAE: 16.61020111475764\n",
      "Trial: 8 - MSE: 988.9816754113762 - RMSE: 31.44807904167401 - MAE: 16.620645110465382\n",
      "Trial: 9 - MSE: 679.9651806647039 - RMSE: 26.076141981986215 - MAE: 15.53475800921466\n",
      "Trial: 10 - MSE: 526.3832188955429 - RMSE: 22.94304293016824 - MAE: 15.036351154739792\n",
      "Trial: 11 - MSE: 507.6879352717882 - RMSE: 22.53193145897147 - MAE: 14.938373671145051\n",
      "Trial: 12 - MSE: 480.01388436396445 - RMSE: 21.90921916372111 - MAE: 14.880598751068115\n",
      "Trial: 13 - MSE: 808.2436001477566 - RMSE: 28.429625395839402 - MAE: 15.935101360217944\n",
      "Trial: 14 - MSE: 478.37684235554383 - RMSE: 21.871827595231814 - MAE: 14.189773867364831\n",
      "Trial: 15 - MSE: 928.0582516802593 - RMSE: 30.464048510995042 - MAE: 16.26497575481518\n",
      "Trial: 16 - MSE: 711.9120230282579 - RMSE: 26.68167953911931 - MAE: 15.585813342120197\n",
      "Trial: 17 - MSE: 889.7409662486701 - RMSE: 29.828526048879286 - MAE: 16.240465359868228\n",
      "Trial: 18 - MSE: 642.1217774475082 - RMSE: 25.34012189093628 - MAE: 15.332558104231552\n",
      "Trial: 19 - MSE: 987.8480304309394 - RMSE: 31.430049800007307 - MAE: 16.583994075465846\n",
      "Trial: 20 - MSE: 843.4742467569343 - RMSE: 29.042628096591642 - MAE: 15.718297531952727\n",
      "Trial: 21 - MSE: 478.6222212536886 - RMSE: 21.877436350123123 - MAE: 14.873513332366942\n",
      "Trial: 22 - MSE: 480.662571950667 - RMSE: 21.924018152488994 - MAE: 14.83209312133789\n",
      "Trial: 23 - MSE: 617.8782177297882 - RMSE: 24.8571562679601 - MAE: 15.238095588374783\n",
      "Trial: 24 - MSE: 591.7939984228395 - RMSE: 24.326816446523363 - MAE: 15.116964698276004\n",
      "Trial: 25 - MSE: 790.6994555444572 - RMSE: 28.119378647908587 - MAE: 15.4769661237562\n",
      "Trial: 26 - MSE: 605.037375875783 - RMSE: 24.597507513481585 - MAE: 15.261922985592403\n",
      "Trial: 27 - MSE: 951.2493714822746 - RMSE: 30.842330837377947 - MAE: 16.487809730529783\n",
      "Trial: 28 - MSE: 760.1924657869737 - RMSE: 27.571588017141373 - MAE: 15.782768657375025\n",
      "Trial: 29 - MSE: 488.66481525552774 - RMSE: 22.10576429928465 - MAE: 14.383379023577715\n",
      "Trial: 30 - MSE: 935.6660932819597 - RMSE: 30.58865955353323 - MAE: 16.063695236288535\n",
      "Trial: 31 - MSE: 554.3108143996345 - RMSE: 23.543806285297933 - MAE: 15.107385660944757\n",
      "Trial: 32 - MSE: 477.980310517575 - RMSE: 21.862760816456255 - MAE: 14.821893994656124\n",
      "Trial: 33 - MSE: 647.4366561358835 - RMSE: 25.44477659827029 - MAE: 15.439312565983954\n",
      "Trial: 34 - MSE: 1001.4878772945153 - RMSE: 31.646293263106113 - MAE: 16.676376172452358\n",
      "Trial: 35 - MSE: 605.123370683592 - RMSE: 24.599255490432878 - MAE: 14.188751563531\n",
      "Trial: 36 - MSE: 468.160062646834 - RMSE: 21.637006785755602 - MAE: 14.291654948713973\n",
      "Trial: 37 - MSE: 977.1536502779667 - RMSE: 31.259456973497905 - MAE: 16.46869568658777\n",
      "Trial: 38 - MSE: 654.4136029571634 - RMSE: 25.5815090046925 - MAE: 15.303809569281501\n",
      "Trial: 39 - MSE: 925.3800206671197 - RMSE: 30.420059511235667 - MAE: 16.17925316454913\n",
      "Trial: 40 - MSE: 695.0536478767857 - RMSE: 26.3638701232726 - MAE: 14.751824348635287\n",
      "Trial: 41 - MSE: 485.172790405162 - RMSE: 22.0266382002602 - MAE: 14.779947815498145\n",
      "Trial: 42 - MSE: 579.929749105931 - RMSE: 24.081730608615548 - MAE: 15.051465560088285\n",
      "Trial: 43 - MSE: 474.03076155434917 - RMSE: 21.772247508108784 - MAE: 14.767329325330579\n",
      "Trial: 44 - MSE: 989.7493516532462 - RMSE: 31.460282129269697 - MAE: 16.625224715361725\n",
      "Trial: 45 - MSE: 527.928011788255 - RMSE: 22.976684090361147 - MAE: 14.971519587274498\n",
      "Trial: 46 - MSE: 658.3066960080534 - RMSE: 25.657488107919946 - MAE: 15.145193934260188\n",
      "Trial: 47 - MSE: 667.5383245316556 - RMSE: 25.83676304283599 - MAE: 15.137017482654468\n",
      "Trial: 48 - MSE: 535.8605603585935 - RMSE: 23.148662172112527 - MAE: 14.862458648599159\n",
      "Trial: 49 - MSE: 582.7161872861892 - RMSE: 24.139515059051813 - MAE: 15.127177619727881\n",
      "Trial: 50 - MSE: 630.0203944156194 - RMSE: 25.100207059218047 - MAE: 15.213887162553942\n",
      "Trial: 51 - MSE: 480.287823400172 - RMSE: 21.91546995617872 - MAE: 14.871791762068463\n",
      "Trial: 52 - MSE: 513.9624757692402 - RMSE: 22.670740520971965 - MAE: 15.007456900416193\n",
      "Trial: 53 - MSE: 552.3298199773631 - RMSE: 23.501698236028883 - MAE: 15.116863229906237\n",
      "Trial: 54 - MSE: 483.06352284874856 - RMSE: 21.978706123171776 - MAE: 14.823544576799547\n",
      "Trial: 55 - MSE: 680.0598657240039 - RMSE: 26.077957468406222 - MAE: 15.57741679701934\n",
      "Trial: 56 - MSE: 537.1572678074149 - RMSE: 23.176653507515162 - MAE: 14.965631518286626\n",
      "Trial: 57 - MSE: 480.59330412101417 - RMSE: 21.922438370788367 - MAE: 13.44799426253035\n",
      "Trial: 58 - MSE: 752.3571874438037 - RMSE: 27.429130271370322 - MAE: 15.49512438449344\n",
      "Trial: 59 - MSE: 1001.4878772945153 - RMSE: 31.646293263106113 - MAE: 16.676376172452358\n",
      "Trial: 60 - MSE: 927.5706119214374 - RMSE: 30.456043930908645 - MAE: 16.131752169964763\n",
      "Trial: 61 - MSE: 478.80176052151825 - RMSE: 21.88153926307558 - MAE: 14.863781199377936\n",
      "Trial: 62 - MSE: 476.5753515132742 - RMSE: 21.83060584393558 - MAE: 14.858197338310447\n",
      "Trial: 63 - MSE: 506.55234565355613 - RMSE: 22.50671778944136 - MAE: 14.936755729159792\n",
      "Trial: 64 - MSE: 551.7647086046031 - RMSE: 23.489672381806503 - MAE: 15.158751479793239\n",
      "Trial: 65 - MSE: 513.9867047346422 - RMSE: 22.671274881105433 - MAE: 14.895978966068576\n",
      "Trial: 66 - MSE: 899.7799503202338 - RMSE: 29.996332281134535 - MAE: 16.31355267581424\n",
      "Trial: 67 - MSE: 628.5507607497706 - RMSE: 25.070914637279802 - MAE: 15.303270092959016\n",
      "Trial: 68 - MSE: 504.68156402957584 - RMSE: 22.465118829633994 - MAE: 14.965900621981234\n",
      "Trial: 69 - MSE: 667.065469416037 - RMSE: 25.827610602145082 - MAE: 15.43517528090606\n",
      "Trial: 70 - MSE: 964.7586295636218 - RMSE: 31.06056389642052 - MAE: 16.570386207333126\n",
      "Trial: 71 - MSE: 933.7174048500315 - RMSE: 30.556789832212928 - MAE: 16.438230715365023\n",
      "Trial: 72 - MSE: 520.0702215019309 - RMSE: 22.805048158290102 - MAE: 14.944582999502645\n",
      "Trial: 73 - MSE: 482.51034529644545 - RMSE: 21.966118120788785 - MAE: 14.899031556412979\n",
      "Trial: 74 - MSE: 615.8758663817965 - RMSE: 24.81684642298043 - MAE: 15.244234407991977\n",
      "Trial: 75 - MSE: 1001.4878772945153 - RMSE: 31.646293263106113 - MAE: 16.676376172452358\n",
      "Trial: 76 - MSE: 568.7632969300972 - RMSE: 23.848758813198167 - MAE: 15.091240390365188\n",
      "Trial: 77 - MSE: 979.6692189553854 - RMSE: 31.299668032670656 - MAE: 16.598433723243506\n",
      "Trial: 78 - MSE: 481.416859011526 - RMSE: 21.941213708715523 - MAE: 13.981921563060862\n",
      "Trial: 79 - MSE: 480.88280500731895 - RMSE: 21.929040220842293 - MAE: 13.598327807782148\n",
      "Trial: 80 - MSE: 566.8301868912764 - RMSE: 23.808195792442493 - MAE: 15.114047733306885\n",
      "Trial: 81 - MSE: 497.381024784863 - RMSE: 22.302040821074268 - MAE: 14.934724562670732\n",
      "Trial: 82 - MSE: 525.5030787093945 - RMSE: 22.92385392357477 - MAE: 15.004388491965628\n",
      "Trial: 83 - MSE: 480.61427863970175 - RMSE: 21.922916745718435 - MAE: 14.905265544994457\n",
      "Trial: 84 - MSE: 511.5397740758729 - RMSE: 22.617245059376106 - MAE: 14.94020154647827\n",
      "Trial: 85 - MSE: 588.4313222277757 - RMSE: 24.25760339002548 - MAE: 15.206393087026234\n",
      "Trial: 86 - MSE: 526.8278692502527 - RMSE: 22.952731193700078 - MAE: 14.920151836189063\n",
      "Trial: 87 - MSE: 499.57279698021017 - RMSE: 22.35112518376223 - MAE: 14.967958419181205\n",
      "Trial: 88 - MSE: 1001.4878772945153 - RMSE: 31.646293263106113 - MAE: 16.676376172452358\n",
      "Trial: 89 - MSE: 566.3828950599814 - RMSE: 23.798800286148488 - MAE: 14.9686501114304\n",
      "Trial: 90 - MSE: 900.9869661579316 - RMSE: 30.016444928704193 - MAE: 15.831648681331323\n",
      "Trial: 91 - MSE: 520.0150600022905 - RMSE: 22.803838711986423 - MAE: 14.640008236694335\n",
      "Trial: 92 - MSE: 469.2071200891404 - RMSE: 21.661189258421164 - MAE: 13.601088241412187\n",
      "Trial: 93 - MSE: 475.7870881978463 - RMSE: 21.812544285292496 - MAE: 13.801645927882838\n",
      "Trial: 94 - MSE: 602.7451155017582 - RMSE: 24.550867917484265 - MAE: 14.484561879544643\n",
      "Trial: 95 - MSE: 512.1853237187921 - RMSE: 22.6315117417903 - MAE: 13.908815919453387\n",
      "Trial: 96 - MSE: 454.1139050433705 - RMSE: 21.309948499312956 - MAE: 13.187473265611802\n",
      "Trial: 97 - MSE: 550.411936361021 - RMSE: 23.460859667987894 - MAE: 13.970984937760635\n",
      "Trial: 98 - MSE: 522.3936726402857 - RMSE: 22.85593298555729 - MAE: 14.41161012820682\n",
      "Trial: 99 - MSE: 986.0326478613755 - RMSE: 31.401156791770834 - MAE: 16.59610027705012\n"
     ]
    }
   ],
   "source": [
    "# configuration optuna\n",
    "study_g = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "study_g.optimize(lambda trial: objective(trial, X_g_train, y_g_train, X_g_test, y_g_test, y_g_scaler), n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pruebas: 100\n",
      "Mejor prueba: 96\n",
      "Mejores parametros: {'booster': 'dart', 'lambda': 8.454949858261484e-08, 'alpha': 2.958443409627235e-07, 'learning_rate': 0.0909507221631542, 'subsample': 0.8959347658610356, 'colsample_bytree': 0.8483727513060559, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.6139540352836711, 'gamma': 0.9107525035496924, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 1.9309378936570674e-05, 'skip_drop': 1.3380205255498052e-05}\n",
      "Mejor valor de pérdida: 0.024950343190563686\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(f'Número de pruebas: {len(study_g.trials)}')\n",
    "trial = study_g.best_trial\n",
    "print(f'Mejor prueba: {trial.number}')\n",
    "print(f'Mejores parametros: {trial.params}')\n",
    "print(f'Mejor valor de pérdida: {trial.value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 - MSE: 1064.1945808639987 - RMSE: 32.621995353809965 - MAE: 16.23366529501638\n",
      "Trial: 1 - MSE: 1103.3017138375524 - RMSE: 33.215985817638355 - MAE: 16.529044411936113\n",
      "Trial: 2 - MSE: 1082.336915698488 - RMSE: 32.898889277580295 - MAE: 16.33358034416937\n",
      "Trial: 3 - MSE: 991.8793342478538 - RMSE: 31.494115867060845 - MAE: 15.691470216812625\n",
      "Trial: 4 - MSE: 1071.0287872265 - RMSE: 32.72657616107283 - MAE: 16.26521556829637\n",
      "Trial: 5 - MSE: 580.4621564128688 - RMSE: 24.092782247238876 - MAE: 13.038607426821802\n",
      "Trial: 6 - MSE: 942.008390000099 - RMSE: 30.6921551866287 - MAE: 15.301362894365862\n",
      "Trial: 7 - MSE: 785.1822172802204 - RMSE: 28.021103070368596 - MAE: 13.861321516221569\n",
      "Trial: 8 - MSE: 999.8900289005114 - RMSE: 31.62103775812096 - MAE: 15.717443522545599\n",
      "Trial: 9 - MSE: 478.59366311619897 - RMSE: 21.87678365565192 - MAE: 12.037704514042021\n",
      "Trial: 10 - MSE: 1088.3549632029446 - RMSE: 32.990225267538634 - MAE: 16.420683817463537\n",
      "Trial: 11 - MSE: 372.3120087723378 - RMSE: 19.29538827731481 - MAE: 10.338612463625015\n",
      "Trial: 12 - MSE: 437.0757968611961 - RMSE: 20.90635780955631 - MAE: 12.21537351679648\n",
      "Trial: 13 - MSE: 751.8467552179629 - RMSE: 27.41982412813698 - MAE: 14.120228836551789\n",
      "Trial: 14 - MSE: 492.1893890831354 - RMSE: 22.18534176169336 - MAE: 12.65360735249673\n",
      "Trial: 15 - MSE: 862.3931724192018 - RMSE: 29.366531501340123 - MAE: 14.966425231539818\n",
      "Trial: 16 - MSE: 871.553204741295 - RMSE: 29.522079952830136 - MAE: 14.635332817176078\n",
      "Trial: 17 - MSE: 601.7593551061494 - RMSE: 24.530783825759613 - MAE: 13.261960679035802\n",
      "Trial: 18 - MSE: 1082.3415749904386 - RMSE: 32.89896008980282 - MAE: 16.38190071573565\n",
      "Trial: 19 - MSE: 1004.0583962219832 - RMSE: 31.686880506322854 - MAE: 15.684034351521154\n",
      "Trial: 20 - MSE: 678.3922437057914 - RMSE: 26.045964057907156 - MAE: 13.615286696649367\n",
      "Trial: 21 - MSE: 495.33685915736174 - RMSE: 22.256164520360684 - MAE: 12.11705143713182\n",
      "Trial: 22 - MSE: 464.5300980871228 - RMSE: 21.5529603091344 - MAE: 11.956216923965945\n",
      "Trial: 23 - MSE: 598.8637374231666 - RMSE: 24.471692573730298 - MAE: 13.072969108187767\n",
      "Trial: 24 - MSE: 799.7347068655656 - RMSE: 28.279581094237688 - MAE: 14.28179398163826\n",
      "Trial: 25 - MSE: 393.5170386409675 - RMSE: 19.83726388998663 - MAE: 10.181978903198242\n",
      "Trial: 26 - MSE: 622.0035388132186 - RMSE: 24.939998773320312 - MAE: 12.23518078716647\n",
      "Trial: 27 - MSE: 817.9732059317971 - RMSE: 28.600230872001664 - MAE: 14.306011662390924\n",
      "Trial: 28 - MSE: 438.4560240879634 - RMSE: 20.93934153902561 - MAE: 12.272526955930648\n",
      "Trial: 29 - MSE: 977.5552179863321 - RMSE: 31.265879453268735 - MAE: 15.581402588678175\n",
      "Trial: 30 - MSE: 864.1683219457586 - RMSE: 29.39673998840277 - MAE: 14.613758414188506\n",
      "Trial: 31 - MSE: 454.19770221174394 - RMSE: 21.311914559976632 - MAE: 12.324461940199328\n",
      "Trial: 32 - MSE: 544.4683290454168 - RMSE: 23.333845140598168 - MAE: 12.703747341180616\n",
      "Trial: 33 - MSE: 543.3706847018149 - RMSE: 23.310312840067482 - MAE: 12.711921454940303\n",
      "Trial: 34 - MSE: 637.8886216201727 - RMSE: 25.25645702825661 - MAE: 13.317712791344428\n",
      "Trial: 35 - MSE: 513.8828983061653 - RMSE: 22.6689853832536 - MAE: 12.533932556939893\n",
      "Trial: 36 - MSE: 896.7419210081572 - RMSE: 29.94564945043198 - MAE: 14.91125180496708\n",
      "Trial: 37 - MSE: 1038.5792589172468 - RMSE: 32.226995809681775 - MAE: 16.01551215239494\n",
      "Trial: 38 - MSE: 1076.1785365418307 - RMSE: 32.8051602121043 - MAE: 16.341753971715125\n",
      "Trial: 39 - MSE: 835.0353202020807 - RMSE: 28.896977700134673 - MAE: 14.393691746767107\n",
      "Trial: 40 - MSE: 1081.854244178703 - RMSE: 32.89155277846735 - MAE: 16.430383104681198\n",
      "Trial: 41 - MSE: 453.84251517962053 - RMSE: 21.30357986770347 - MAE: 12.332685872970089\n",
      "Trial: 42 - MSE: 524.3278874867395 - RMSE: 22.89820708017856 - MAE: 12.023820697562924\n",
      "Trial: 43 - MSE: 506.35415970440926 - RMSE: 22.502314541051312 - MAE: 12.526382285530335\n",
      "Trial: 44 - MSE: 575.0129959717942 - RMSE: 23.979428599776814 - MAE: 12.40814647689327\n",
      "Trial: 45 - MSE: 833.4687589357719 - RMSE: 28.8698590044318 - MAE: 14.604960175101986\n",
      "Trial: 46 - MSE: 450.47046996159617 - RMSE: 21.22428962207207 - MAE: 12.324135458669353\n",
      "Trial: 47 - MSE: 811.5461065630076 - RMSE: 28.48764831577025 - MAE: 14.455410414418866\n",
      "Trial: 48 - MSE: 713.4448469850964 - RMSE: 26.71038837203788 - MAE: 13.221651542663572\n",
      "Trial: 49 - MSE: 711.1854185427198 - RMSE: 26.668059894614004 - MAE: 13.582339580412834\n",
      "Trial: 50 - MSE: 1037.2102945413144 - RMSE: 32.205749401951735 - MAE: 16.05291274507584\n",
      "Trial: 51 - MSE: 491.30302074311044 - RMSE: 22.16535631888444 - MAE: 12.671961501066145\n",
      "Trial: 52 - MSE: 435.3987818380203 - RMSE: 20.866211487426757 - MAE: 12.258716199468797\n",
      "Trial: 53 - MSE: 488.72869752055897 - RMSE: 22.107209175302046 - MAE: 12.52305414871708\n",
      "Trial: 54 - MSE: 643.2653117460023 - RMSE: 25.362675563630948 - MAE: 13.345360571732058\n",
      "Trial: 55 - MSE: 512.092538036978 - RMSE: 22.62946172662925 - MAE: 12.62295698776245\n",
      "Trial: 56 - MSE: 412.93636298347593 - RMSE: 20.320835686149227 - MAE: 11.974995852365799\n",
      "Trial: 57 - MSE: 996.5627745737902 - RMSE: 31.568382514373305 - MAE: 15.783004734654579\n",
      "Trial: 58 - MSE: 1053.0594991477217 - RMSE: 32.450878249251154 - MAE: 16.16076445524154\n",
      "Trial: 59 - MSE: 560.5353484427051 - RMSE: 23.675627730700302 - MAE: 12.435947479740266\n",
      "Trial: 60 - MSE: 587.1632480028583 - RMSE: 24.231451628056835 - MAE: 13.046166221027988\n",
      "Trial: 61 - MSE: 444.5546478407212 - RMSE: 21.084464608823275 - MAE: 12.262961473452657\n",
      "Trial: 62 - MSE: 494.6271634071448 - RMSE: 22.240215003617767 - MAE: 12.522339700071273\n",
      "Trial: 63 - MSE: 542.105677496172 - RMSE: 23.28316296159463 - MAE: 12.86131176359115\n",
      "Trial: 64 - MSE: 474.9767678009829 - RMSE: 21.793961727987476 - MAE: 12.371491568879158\n",
      "Trial: 65 - MSE: 431.310306692445 - RMSE: 20.76801162105908 - MAE: 12.178579104122038\n",
      "Trial: 66 - MSE: 996.3516645735286 - RMSE: 31.565038643624828 - MAE: 15.725379351215977\n",
      "Trial: 67 - MSE: 648.2915392608016 - RMSE: 25.46156985067499 - MAE: 13.383598881383096\n",
      "Trial: 68 - MSE: 527.4505964183912 - RMSE: 22.966292613706532 - MAE: 12.114522406842632\n",
      "Trial: 69 - MSE: 477.79010006427166 - RMSE: 21.858410282183645 - MAE: 12.388827321550924\n",
      "Trial: 70 - MSE: 583.9163829800048 - RMSE: 24.164361836804314 - MAE: 13.077655254290178\n",
      "Trial: 71 - MSE: 448.4007971963965 - RMSE: 21.175476315691142 - MAE: 12.252269628610916\n",
      "Trial: 72 - MSE: 442.80343247470336 - RMSE: 21.042895059252263 - MAE: 12.240044526696973\n",
      "Trial: 73 - MSE: 523.9198822168524 - RMSE: 22.889296236818915 - MAE: 12.69688093192808\n",
      "Trial: 74 - MSE: 530.1305302889939 - RMSE: 23.024563628633526 - MAE: 12.848855254117904\n",
      "Trial: 75 - MSE: 563.43794383235 - RMSE: 23.73684780741432 - MAE: 12.876199313822099\n",
      "Trial: 76 - MSE: 797.8903345690319 - RMSE: 28.24695265987168 - MAE: 14.012923426523516\n",
      "Trial: 77 - MSE: 427.69937437288627 - RMSE: 20.68089394520668 - MAE: 12.158403750265798\n",
      "Trial: 78 - MSE: 460.0884737609066 - RMSE: 21.449673045547957 - MAE: 12.259110981652043\n",
      "Trial: 79 - MSE: 512.5525804626872 - RMSE: 22.63962412370592 - MAE: 11.614854899892498\n",
      "Trial: 80 - MSE: 757.0315654178204 - RMSE: 27.514206610727854 - MAE: 13.791130130152547\n",
      "Trial: 81 - MSE: 464.7821431787129 - RMSE: 21.558806626961356 - MAE: 12.36371919353854\n",
      "Trial: 82 - MSE: 474.6049851513312 - RMSE: 21.785430570712418 - MAE: 12.375228132678615\n",
      "Trial: 83 - MSE: 432.19893617253723 - RMSE: 20.789394800535614 - MAE: 12.183974594854538\n",
      "Trial: 84 - MSE: 424.55894881203426 - RMSE: 20.60482828882673 - MAE: 12.142093181240941\n",
      "Trial: 85 - MSE: 514.4712190383851 - RMSE: 22.681958007155934 - MAE: 12.579719055323446\n",
      "Trial: 86 - MSE: 441.3602031023514 - RMSE: 21.008574513811055 - MAE: 10.758847142422582\n",
      "Trial: 87 - MSE: 540.0499181996377 - RMSE: 23.238974121067344 - MAE: 12.734062432565995\n",
      "Trial: 88 - MSE: 707.653126347362 - RMSE: 26.60175043765658 - MAE: 13.699252268046717\n",
      "Trial: 89 - MSE: 609.0700681738117 - RMSE: 24.679344970517587 - MAE: 13.142900211063507\n",
      "Trial: 90 - MSE: 1079.5673429188691 - RMSE: 32.856770123048754 - MAE: 16.362431154312624\n",
      "Trial: 91 - MSE: 435.6517207515452 - RMSE: 20.87227157622153 - MAE: 12.20175435982981\n",
      "Trial: 92 - MSE: 426.60307193107525 - RMSE: 20.6543717389582 - MAE: 12.159342594860446\n",
      "Trial: 93 - MSE: 425.62896004863757 - RMSE: 20.63077701029793 - MAE: 12.14728841154037\n",
      "Trial: 94 - MSE: 490.32461392921965 - RMSE: 22.143274688474143 - MAE: 12.480802853639663\n",
      "Trial: 95 - MSE: 697.6221052403547 - RMSE: 26.41253689520101 - MAE: 14.071207823722593\n",
      "Trial: 96 - MSE: 566.9281725310587 - RMSE: 23.810253516732214 - MAE: 12.903145922802338\n",
      "Trial: 97 - MSE: 1089.2809672750732 - RMSE: 33.004256805373956 - MAE: 16.43045817442863\n",
      "Trial: 98 - MSE: 690.9918019190206 - RMSE: 26.286722920878148 - MAE: 13.151424929415793\n",
      "Trial: 99 - MSE: 437.65069754387235 - RMSE: 20.920102713511525 - MAE: 12.218841384100143\n"
     ]
    }
   ],
   "source": [
    "# configuration optuna\n",
    "study_st = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "study_st.optimize(lambda trial: objective(trial, X_st_train, y_st_train, X_st_test, y_st_test, y_st_scaler), n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pruebas: 100\n",
      "Mejor prueba: 11\n",
      "Mejores parametros: {'booster': 'gbtree', 'lambda': 0.0021535957566553797, 'alpha': 0.08596518740279382, 'learning_rate': 0.09708281774708119, 'subsample': 0.8307814364526688, 'colsample_bytree': 0.8887109093150083, 'max_depth': 7, 'min_child_weight': 9, 'eta': 2.4113747198291302e-08, 'gamma': 0.8835542456640489, 'grow_policy': 'depthwise'}\n",
      "Mejor valor de pérdida en validación: 0.020981349834958165\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(f'Número de pruebas: {len(study_st.trials)}')\n",
    "trial = study_st.best_trial\n",
    "print(f'Mejor prueba: {trial.number}')\n",
    "print(f'Mejores parametros: {trial.params}')\n",
    "print(f'Mejor valor de pérdida en validación: {trial.value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 - MSE: 700.3482069971574 - RMSE: 26.464092786210475 - MAE: 26.447168843587242\n",
      "Trial: 1 - MSE: 565.767503184766 - RMSE: 23.78586771981981 - MAE: 23.770393976211544\n",
      "Trial: 2 - MSE: 572.2918166349716 - RMSE: 23.922621441534613 - MAE: 23.906382911046343\n",
      "Trial: 3 - MSE: 575.985425910368 - RMSE: 23.999696371212032 - MAE: 23.98324116134643\n",
      "Trial: 4 - MSE: 556.2080890401476 - RMSE: 23.584064302832697 - MAE: 23.568480015436805\n",
      "Trial: 5 - MSE: 562.3980763499537 - RMSE: 23.71493361470687 - MAE: 23.69944413566589\n",
      "Trial: 6 - MSE: 579.9764359019724 - RMSE: 24.082699929658478 - MAE: 24.067213297526038\n",
      "Trial: 7 - MSE: 552.0827618206087 - RMSE: 23.496441471435812 - MAE: 23.48080786132812\n",
      "Trial: 8 - MSE: 555.9579222382611 - RMSE: 23.578759980929046 - MAE: 23.563163010915115\n",
      "Trial: 9 - MSE: 583.2944161730646 - RMSE: 24.151488901785427 - MAE: 24.136279583613074\n",
      "Trial: 10 - MSE: 552.0827618206087 - RMSE: 23.496441471435812 - MAE: 23.48080786132812\n",
      "Trial: 11 - MSE: 552.0827618206087 - RMSE: 23.496441471435812 - MAE: 23.48080786132812\n",
      "Trial: 12 - MSE: 552.0827618206087 - RMSE: 23.496441471435812 - MAE: 23.48080786132812\n",
      "Trial: 13 - MSE: 552.3521382412359 - RMSE: 23.502173053597318 - MAE: 23.486543258666988\n",
      "Trial: 14 - MSE: 553.0494469766916 - RMSE: 23.51700335877621 - MAE: 23.501352279027298\n",
      "Trial: 15 - MSE: 552.0827618206087 - RMSE: 23.496441471435812 - MAE: 23.48080786132812\n",
      "Trial: 16 - MSE: 551.6314275900502 - RMSE: 23.48683519740474 - MAE: 23.471053696314492\n",
      "Trial: 17 - MSE: 551.3846769788498 - RMSE: 23.481581654114567 - MAE: 23.465753079096473\n",
      "Trial: 18 - MSE: 551.4223803350254 - RMSE: 23.482384468682593 - MAE: 23.466592280705765\n",
      "Trial: 19 - MSE: 550.9952791372061 - RMSE: 23.473288630637295 - MAE: 23.457454236984248\n",
      "Trial: 20 - MSE: 543.9039599023773 - RMSE: 23.321748645896545 - MAE: 23.30472175343831\n",
      "Trial: 21 - MSE: 543.099076289097 - RMSE: 23.304486183760776 - MAE: 23.287160921732582\n",
      "Trial: 22 - MSE: 545.062322794861 - RMSE: 23.34656982931028 - MAE: 23.32988783582051\n",
      "Trial: 23 - MSE: 543.506980449453 - RMSE: 23.31323616423625 - MAE: 23.295808188756304\n",
      "Trial: 24 - MSE: 545.0783166445817 - RMSE: 23.346912357838278 - MAE: 23.329204480489093\n",
      "Trial: 25 - MSE: 534.3212785447005 - RMSE: 23.11539051248541 - MAE: 23.097158861796057\n",
      "Trial: 26 - MSE: 543.4519589935364 - RMSE: 23.31205608678772 - MAE: 23.296048196792597\n",
      "Trial: 27 - MSE: 543.3706428404403 - RMSE: 23.310311942152133 - MAE: 23.294338608423864\n",
      "Trial: 28 - MSE: 613.3647819902458 - RMSE: 24.76620241357657 - MAE: 24.751370319366455\n",
      "Trial: 29 - MSE: 679.1808042024949 - RMSE: 26.0610975249028 - MAE: 26.04508117103577\n",
      "Trial: 30 - MSE: 613.49526923731 - RMSE: 24.76883665490388 - MAE: 24.751132520675657\n",
      "Trial: 31 - MSE: 536.9304765933257 - RMSE: 23.171760325735413 - MAE: 23.155078205108637\n",
      "Trial: 32 - MSE: 540.7427650421528 - RMSE: 23.2538763444324 - MAE: 23.237394047419226\n",
      "Trial: 33 - MSE: 538.0321945623172 - RMSE: 23.195521002174473 - MAE: 23.17858731015523\n",
      "Trial: 34 - MSE: 563.2265350864407 - RMSE: 23.732394213109654 - MAE: 23.71689119402567\n",
      "Trial: 35 - MSE: 535.514855404699 - RMSE: 23.141193906207583 - MAE: 23.12315058771769\n",
      "Trial: 36 - MSE: 533.7172792410445 - RMSE: 23.102321944796902 - MAE: 23.084416660308833\n",
      "Trial: 37 - MSE: 631.371749497322 - RMSE: 25.12711184154124 - MAE: 25.112491687774657\n",
      "Trial: 38 - MSE: 594.9238353400841 - RMSE: 24.391060562019113 - MAE: 24.375997989018753\n",
      "Trial: 39 - MSE: 560.8891376928543 - RMSE: 23.683098143884266 - MAE: 23.653344536463415\n",
      "Trial: 40 - MSE: 555.7345755050238 - RMSE: 23.574023320278272 - MAE: 23.55844022496541\n",
      "Trial: 41 - MSE: 539.4246652469459 - RMSE: 23.225517545298015 - MAE: 23.208381128946936\n",
      "Trial: 42 - MSE: 549.7410478722977 - RMSE: 23.446557271213564 - MAE: 23.430817255020138\n",
      "Trial: 43 - MSE: 531.149134921129 - RMSE: 23.046672968589824 - MAE: 23.02772358322143\n",
      "Trial: 44 - MSE: 524.9553419692147 - RMSE: 22.911903935928475 - MAE: 22.8911347395579\n",
      "Trial: 45 - MSE: 538.824500593435 - RMSE: 23.212593577483645 - MAE: 23.194966761906937\n",
      "Trial: 46 - MSE: 535.8516264232852 - RMSE: 23.148469202590594 - MAE: 23.127437767028805\n",
      "Trial: 47 - MSE: 617.3559547532451 - RMSE: 24.846648763027282 - MAE: 24.831863006591796\n",
      "Trial: 48 - MSE: 547.4327996152958 - RMSE: 23.397281885195465 - MAE: 23.380421925226845\n",
      "Trial: 49 - MSE: 540.3670051909872 - RMSE: 23.2457954303781 - MAE: 23.228460439682003\n",
      "Trial: 50 - MSE: 539.2044865863357 - RMSE: 23.220777045274254 - MAE: 23.200481860478714\n",
      "Trial: 51 - MSE: 535.5944372494197 - RMSE: 23.14291332674907 - MAE: 23.121118768692014\n",
      "Trial: 52 - MSE: 532.4463960165178 - RMSE: 23.074800021159835 - MAE: 23.05295108222961\n",
      "Trial: 53 - MSE: 522.89427451345 - RMSE: 22.86688160885629 - MAE: 22.847187996546424\n",
      "Trial: 54 - MSE: 511.41052437621147 - RMSE: 22.61438755253415 - MAE: 22.592173926671343\n",
      "Trial: 55 - MSE: 513.1673597967532 - RMSE: 22.6531975623035 - MAE: 22.63166594568888\n",
      "Trial: 56 - MSE: 533.6243541873877 - RMSE: 23.100310694607284 - MAE: 23.072405593236283\n",
      "Trial: 57 - MSE: 524.8514956561858 - RMSE: 22.909637615121408 - MAE: 22.880413421630855\n",
      "Trial: 58 - MSE: 528.1108754114333 - RMSE: 22.98066307597397 - MAE: 22.963405164718623\n",
      "Trial: 59 - MSE: 691.4651640092796 - RMSE: 26.29572520409505 - MAE: 26.280743281682334\n",
      "Trial: 60 - MSE: 516.1688570754965 - RMSE: 22.719349838309558 - MAE: 22.699096394220984\n",
      "Trial: 61 - MSE: 515.174071049212 - RMSE: 22.697446355244722 - MAE: 22.6771074142456\n",
      "Trial: 62 - MSE: 517.046194812268 - RMSE: 22.73864980187408 - MAE: 22.718358867009478\n",
      "Trial: 63 - MSE: 520.8072410249205 - RMSE: 22.821201568386368 - MAE: 22.794620546340937\n",
      "Trial: 64 - MSE: 518.3960601233433 - RMSE: 22.768312632326168 - MAE: 22.748610068003334\n",
      "Trial: 65 - MSE: 515.7361488232988 - RMSE: 22.709824940393062 - MAE: 22.68915386263529\n",
      "Trial: 66 - MSE: 523.6283776388673 - RMSE: 22.88292764571149 - MAE: 22.864096546808874\n",
      "Trial: 67 - MSE: 606.84350567344 - RMSE: 24.634193830394366 - MAE: 24.61799985631307\n",
      "Trial: 68 - MSE: 576.4301641673371 - RMSE: 24.008960080922645 - MAE: 23.980171760559077\n",
      "Trial: 69 - MSE: 528.1534917049655 - RMSE: 22.981590277980448 - MAE: 22.963758008321122\n",
      "Trial: 70 - MSE: 537.6800544156918 - RMSE: 23.187929066988534 - MAE: 23.17156187756856\n",
      "Trial: 71 - MSE: 521.1663518293703 - RMSE: 22.829068133179906 - MAE: 22.801573308944697\n",
      "Trial: 72 - MSE: 517.0266804102057 - RMSE: 22.73822069578457 - MAE: 22.717858394622798\n",
      "Trial: 73 - MSE: 510.1785511509951 - RMSE: 22.58713242425862 - MAE: 22.5648519522349\n",
      "Trial: 74 - MSE: 507.9133968552836 - RMSE: 22.53693406067657 - MAE: 22.513868221282955\n",
      "Trial: 75 - MSE: 517.0233659379186 - RMSE: 22.738147812386096 - MAE: 22.719097471872963\n",
      "Trial: 76 - MSE: 518.8493291589309 - RMSE: 22.778264401813647 - MAE: 22.759597222646075\n",
      "Trial: 77 - MSE: 700.8966591794397 - RMSE: 26.474452953355613 - MAE: 26.460526705423995\n",
      "Trial: 78 - MSE: 535.4550422479759 - RMSE: 23.13990151768101 - MAE: 23.12354262733459\n",
      "Trial: 79 - MSE: 520.6097815472583 - RMSE: 22.816874929473983 - MAE: 22.798271179834998\n",
      "Trial: 80 - MSE: 507.35061490333135 - RMSE: 22.524444830080306 - MAE: 22.49906258646647\n",
      "Trial: 81 - MSE: 506.8811738014409 - RMSE: 22.514021715398627 - MAE: 22.48976729774475\n",
      "Trial: 82 - MSE: 518.3596634720217 - RMSE: 22.767513335277123 - MAE: 22.74625169499715\n",
      "Trial: 83 - MSE: 516.5062612476204 - RMSE: 22.726774105614293 - MAE: 22.69951211675008\n",
      "Trial: 84 - MSE: 523.8824365864634 - RMSE: 22.888478249688497 - MAE: 22.869006380081174\n",
      "Trial: 85 - MSE: 649.7236605216693 - RMSE: 25.48967752878936 - MAE: 25.465659730275476\n",
      "Trial: 86 - MSE: 532.9728234087727 - RMSE: 23.086204179309615 - MAE: 23.05596140289306\n",
      "Trial: 87 - MSE: 536.6180342181435 - RMSE: 23.165017466389777 - MAE: 23.148491033554073\n",
      "Trial: 88 - MSE: 511.8869381101049 - RMSE: 22.624918521623563 - MAE: 22.602830108642575\n",
      "Trial: 89 - MSE: 552.0424936659418 - RMSE: 23.495584556804324 - MAE: 23.479941352844236\n",
      "Trial: 90 - MSE: 525.2944453327253 - RMSE: 22.919302898053537 - MAE: 22.899972439448035\n",
      "Trial: 91 - MSE: 551.5818758464907 - RMSE: 23.485780290347833 - MAE: 23.470126152674354\n",
      "Trial: 92 - MSE: 517.7786888279669 - RMSE: 22.754750906744 - MAE: 22.734178591410316\n",
      "Trial: 93 - MSE: 511.3721815870421 - RMSE: 22.61353978454152 - MAE: 22.588623428980505\n",
      "Trial: 94 - MSE: 556.3207181723111 - RMSE: 23.58645200474864 - MAE: 23.558622281392413\n",
      "Trial: 95 - MSE: 509.60831454522054 - RMSE: 22.574505853843636 - MAE: 22.54767853482564\n",
      "Trial: 96 - MSE: 636.3056727454219 - RMSE: 25.22510005422024 - MAE: 25.206203636169434\n",
      "Trial: 97 - MSE: 518.5395711505265 - RMSE: 22.771463965905365 - MAE: 22.74230173492431\n",
      "Trial: 98 - MSE: 577.6686798168483 - RMSE: 24.03473902119281 - MAE: 24.00591829681396\n",
      "Trial: 99 - MSE: 663.1727483294952 - RMSE: 25.752140655283306 - MAE: 25.71737958653768\n"
     ]
    }
   ],
   "source": [
    "# configuration optuna\n",
    "study_mm = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "study_mm.optimize(lambda trial: objective(trial, X_mm_train, y_mm_train, X_mm_test, y_mm_test, y_mm_scaler), n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials quantity: 100\n",
      "Mejor prueba: 81\n",
      "Mejores parametros: {'booster': 'gblinear', 'lambda': 0.10550649323074619, 'alpha': 3.4087201612681223e-07, 'learning_rate': 0.09056969450973192, 'subsample': 0.4282198239630527, 'colsample_bytree': 0.2660203263926933}\n",
      "Mejor valor de pérdida en validación: 0.13666949367750314\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(f'Trials quantity: {len(study_mm.trials)}')\n",
    "trial = study_mm.best_trial\n",
    "print(f'Mejor prueba: {trial.number}')\n",
    "print(f'Mejores parametros: {trial.params}')\n",
    "print(f'Mejor valor de pérdida en validación: {trial.value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = '../models/xgboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(scaler_g, f'{models_folder}/scaler_g.joblib')\n",
    "#dump(scaler_st, f'{models_folder}/scaler_st.joblib')\n",
    "#dump(scaler_mm, f'{models_folder}/scaler_mm.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "if study_g is not None:\n",
    "\tparams = study_g.best_trial.params\n",
    "else:\n",
    "\tparams = {\n",
    "\t\t'booster': 'gbtree',\n",
    "\t\t'lambda': 6.153362802392881e-07,\n",
    "\t\t'alpha': 0.0011471508220748314,\n",
    "\t\t'learning_rate': 0.001002737827637667,\n",
    "\t\t'subsample': 0.20466176064508526,\n",
    "\t\t'colsample_bytree': 0.11320379521367623,\n",
    "\t\t'max_depth': 9,\n",
    "\t\t'min_child_weight': 2,\n",
    "\t\t'eta': 0.06983382228087344,\n",
    "\t\t'gamma': 7.814049704902547e-05,\n",
    "\t\t'grow_policy': 'lossguide'\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 458.01439054419336 - RMSE: 21.40127076937707 - MAE: 13.495003354294234\n"
     ]
    }
   ],
   "source": [
    "# general models\n",
    "dtrain = xgb.DMatrix(X_g_train, label=y_g_train)\n",
    "dtest = xgb.DMatrix(X_g_test, label=y_g_test)\n",
    "# training\n",
    "model = xgb.train(params, dtrain)\n",
    "# evaluation\n",
    "preds = model.predict(dtest)\n",
    "mse = mean_squared_error(inv_scaling(y_g_test, y_g_scaler), inv_scaling(preds, y_g_scaler))\n",
    "mae = mean_absolute_error(inv_scaling(y_g_test, y_g_scaler), inv_scaling(preds, y_g_scaler))\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save_model(f'{models_folder}/general.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "if study_st is not None:\n",
    "\tparams = study_st.best_trial.params\n",
    "else:\n",
    "\tparams = {\n",
    "\t\t'booster': 'gbtree',\n",
    "\t\t'lambda': 1.932116425524344e-08,\n",
    "\t\t'alpha': 0.002607815095551034,\n",
    "\t\t'learning_rate': 0.0010967660905229464,\n",
    "\t\t'subsample': 0.27592137172367703,\n",
    "\t\t'colsample_bytree': 0.07486753519541206,\n",
    "\t\t'max_depth': 5,\n",
    "\t\t'min_child_weight': 9,\n",
    "\t\t'eta': 0.0027443109965453517,\n",
    "\t\t'gamma': 3.330037397996609e-08,\n",
    "\t\t'grow_policy': 'depthwise'\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 368.44408669144303 - RMSE: 19.19489741289187 - MAE: 10.328600535928048\n"
     ]
    }
   ],
   "source": [
    "# single thread model\n",
    "dtrain = xgb.DMatrix(X_st_train, label=y_st_train)\n",
    "dtest = xgb.DMatrix(X_st_test, label=y_st_test)\n",
    "# training\n",
    "model = xgb.train(params, dtrain)\n",
    "# evaluation\n",
    "preds = model.predict(dtest)\n",
    "mse = mean_squared_error(inv_scaling(y_st_test, y_st_scaler), inv_scaling(preds, y_st_scaler))\n",
    "mae = mean_absolute_error(inv_scaling(y_st_test, y_st_scaler), inv_scaling(preds, y_st_scaler))\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save_model(f'{models_folder}/single_thread.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "if study_mm is not None:\n",
    "\tparams = study_mm.best_trial.params\n",
    "else:\n",
    "\tparams = {\n",
    "\t\t'booster': 'gblinear',\n",
    "\t\t'lambda': 0.026758763366929273,\n",
    "\t\t'alpha': 0.985176822519382,\n",
    "\t\t'learning_rate': 0.05340673377810871,\n",
    "\t\t'subsample': 0.21906996068917262,\n",
    "\t\t'colsample_bytree': 0.15676169098118364\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 506.89576831297796 - RMSE: 22.51434583355639 - MAE: 22.49009060923258\n"
     ]
    }
   ],
   "source": [
    "# multi thread model\n",
    "dtrain = xgb.DMatrix(X_mm_train, label=y_mm_train)\n",
    "dtest = xgb.DMatrix(X_mm_test, label=y_mm_test)\n",
    "# training\n",
    "model = xgb.train(params, dtrain)\n",
    "# evaluation\n",
    "preds = model.predict(dtest)\n",
    "mse = mean_squared_error(inv_scaling(y_mm_test, y_mm_scaler), inv_scaling(preds, y_mm_scaler))\n",
    "mae = mean_absolute_error(inv_scaling(y_mm_test, y_mm_scaler), inv_scaling(preds, y_mm_scaler))\n",
    "print(f\"MSE: {mse} - RMSE: {np.sqrt(mse)} - MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save_model(f'{models_folder}/multi_thread.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = xgb.Booster()\n",
    "model_st = xgb.Booster()\n",
    "model_mm = xgb.Booster()\n",
    "model_g.load_model(f'{models_folder}/general.json')\n",
    "model_st.load_model(f'{models_folder}/single_thread.json')\n",
    "model_mm.load_model(f'{models_folder}/multi_thread.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_val(model, X, y, y_scaler):\n",
    "\tmin_instance = {\"prediction\": float('inf'), \"actual\": 0, \"index\": 0}\n",
    "\tmax_instance = {\"prediction\": 0, \"actual\": 0, \"index\": 0}\n",
    "\t\n",
    "\tdtest = xgb.DMatrix(X)\n",
    "\tpredictions = inv_scaling(model.predict(dtest), y_scaler)\n",
    "\ty_scaled = inv_scaling(y, y_scaler)\n",
    "\tindex_min = np.argmin(np.abs(predictions - y_scaled))\n",
    "\tmin_instance[\"prediction\"] = predictions[index_min].item()\n",
    "\tmin_instance[\"actual\"] = y_scaled[index_min].item()\n",
    "\tmin_instance[\"index\"] = index_min\n",
    "\tindex_max = np.argmax(np.abs(predictions - y_scaled))\n",
    "\tmax_instance[\"prediction\"] = predictions[index_max].item()\n",
    "\tmax_instance[\"actual\"] = y_scaled[index_max].item()\n",
    "\tmax_instance[\"index\"] = index_max\n",
    "\n",
    "\treturn min_instance, max_instance, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set general model\n",
      "Mean prediction: 22.643465042114258 | Std actual: 13.231526374816895\n",
      "Mean actual: 35.041486486486484 | Std actual: 28.83706408578472\n",
      "Mean Error: 13.495003354294234 | Std Error: 16.61021598329717\n",
      "---\n",
      "Min instance\n",
      "total_time                                                           13.47\n",
      "total_cpu_usage                                                       0.99\n",
      "max_ram_usage                                                  1436.714844\n",
      "brand_raw                         Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz\n",
      "count                                                                   12\n",
      "l2_cache_size                                                          1.5\n",
      "l3_cache_size                                                         12.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                              KNP\n",
      "ghz_actual_friendly                                                 4.1729\n",
      "ghz_advertised_friendly                                                2.9\n",
      "total_time_target                                                    18.11\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 8, dtype: object\n",
      "Min Prediction: 18.407390594482422 | Actual: 18.11 | Error: 0.29739059448242244\n",
      "---\n",
      "Max instance\n",
      "total_time                                                          106.93\n",
      "total_cpu_usage                                                       0.99\n",
      "max_ram_usage                                                         15.5\n",
      "brand_raw                         Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz\n",
      "count                                                                   12\n",
      "l2_cache_size                                                          1.5\n",
      "l3_cache_size                                                         12.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                        N_Queens2\n",
      "ghz_actual_friendly                                                    4.0\n",
      "ghz_advertised_friendly                                                2.9\n",
      "total_time_target                                                   155.04\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 1757, dtype: object\n",
      "Max Prediction: 74.55773162841797 | Actual: 155.04 | Error: 80.48226837158202\n"
     ]
    }
   ],
   "source": [
    "# general model\n",
    "print(\"Validation set general model\")\n",
    "min_instance, max_instance, predictions = describe_val(model_g, X_g_test, y_g_test, y_g_scaler)\n",
    "y_scaled = inv_scaling(y_g_test, y_g_scaler)\n",
    "errors = np.abs(predictions - y_scaled)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_scaled)} | Std actual: {np.std(y_scaled)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"---\")\n",
    "print(\"Min instance\")\n",
    "print(g_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(g_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set single thread model\n",
      "Mean prediction: 26.07541847229004 | Std actual: 14.80790901184082\n",
      "Mean actual: 34.75261290322581 | Std actual: 31.49396398818138\n",
      "Mean Error: 10.328600535928048 | Std Error: 16.179125367604698\n",
      "Min instance\n",
      "total_time                                                           13.47\n",
      "total_cpu_usage                                                       0.99\n",
      "max_ram_usage                                                  1436.714844\n",
      "brand_raw                         Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz\n",
      "count                                                                   12\n",
      "l2_cache_size                                                          1.5\n",
      "l3_cache_size                                                         12.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                              KNP\n",
      "ghz_actual_friendly                                                 4.1729\n",
      "ghz_advertised_friendly                                                2.9\n",
      "total_time_target                                                    19.46\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 7, dtype: object\n",
      "Min Prediction: 19.595006942749023 | Actual: 19.46 | Error: 0.13500694274902258\n",
      "---\n",
      "Max instance\n",
      "total_time                                                          106.93\n",
      "total_cpu_usage                                                       0.99\n",
      "max_ram_usage                                                         15.5\n",
      "brand_raw                         Intel(R) Core(TM) i5-10400 CPU @ 2.90GHz\n",
      "count                                                                   12\n",
      "l2_cache_size                                                          1.5\n",
      "l3_cache_size                                                         12.0\n",
      "l2_cache_line_size                                                     256\n",
      "l2_cache_associativity                                                   6\n",
      "benchmark                                                        N_Queens2\n",
      "ghz_actual_friendly                                                    4.0\n",
      "ghz_advertised_friendly                                                2.9\n",
      "total_time_target                                                   155.04\n",
      "brand_raw_target                       13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                            12\n",
      "l2_cache_size_target                                                   7.5\n",
      "l3_cache_size_target                                                  12.0\n",
      "l2_cache_line_size_target                                             1280\n",
      "l2_cache_associativity_target                                            7\n",
      "ghz_advertised_friendly_target                                       2.496\n",
      "Name: 1757, dtype: object\n",
      "Max Prediction: 81.87413024902344 | Actual: 155.04 | Error: 73.16586975097655\n"
     ]
    }
   ],
   "source": [
    "# single thread model\n",
    "print(\"Validation set single thread model\")\n",
    "min_instance, max_instance, predictions = describe_val(model_st, X_st_test, y_st_test, y_st_scaler)\n",
    "y_scaled = inv_scaling(y_st_test, y_st_scaler)\n",
    "errors = np.abs(predictions - y_scaled)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_scaled)} | Std actual: {np.std(y_scaled)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"Min instance\")\n",
    "print(st_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(st_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set multi thread model\n",
      "Mean prediction: 14.043909072875977 | Std actual: 0.5976359248161316\n",
      "Mean actual: 36.534 | Std actual: 0.8569854141115829\n",
      "Mean Error: 22.49009060923258 | Std Error: 1.0447931381312872\n",
      "Min instance\n",
      "total_time                                                        6.79\n",
      "total_cpu_usage                                                  10.72\n",
      "max_ram_usage                                              2383.351562\n",
      "brand_raw                         12th Gen Intel(R) Core(TM) i5-12400F\n",
      "count                                                               12\n",
      "l2_cache_size                                                      7.5\n",
      "l3_cache_size                                                     18.0\n",
      "l2_cache_line_size                                                1280\n",
      "l2_cache_associativity                                               7\n",
      "benchmark                                                  MATRIX_MULT\n",
      "ghz_actual_friendly                                              2.496\n",
      "ghz_advertised_friendly                                          2.496\n",
      "total_time_target                                                35.58\n",
      "brand_raw_target                   13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                        12\n",
      "l2_cache_size_target                                               7.5\n",
      "l3_cache_size_target                                              12.0\n",
      "l2_cache_line_size_target                                         1280\n",
      "l2_cache_associativity_target                                        7\n",
      "ghz_advertised_friendly_target                                   2.496\n",
      "Name: 5269, dtype: object\n",
      "Min Prediction: 15.83336067199707 | Actual: 35.58 | Error: 19.746639328002928\n",
      "---\n",
      "Max instance\n",
      "total_time                                                            23.83\n",
      "total_cpu_usage                                                        1.92\n",
      "max_ram_usage                                                   2332.710938\n",
      "brand_raw                         Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz\n",
      "count                                                                     8\n",
      "l2_cache_size                                                           2.0\n",
      "l3_cache_size                                                          10.0\n",
      "l2_cache_line_size                                                      256\n",
      "l2_cache_associativity                                                    6\n",
      "benchmark                                                       MATRIX_MULT\n",
      "ghz_actual_friendly                                                     1.5\n",
      "ghz_advertised_friendly                                                 3.0\n",
      "total_time_target                                                     38.02\n",
      "brand_raw_target                        13th Gen Intel(R) Core(TM) i5-1335U\n",
      "count_target                                                             12\n",
      "l2_cache_size_target                                                    7.5\n",
      "l3_cache_size_target                                                   12.0\n",
      "l2_cache_line_size_target                                              1280\n",
      "l2_cache_associativity_target                                             7\n",
      "ghz_advertised_friendly_target                                        2.496\n",
      "Name: 15250, dtype: object\n",
      "Max Prediction: 13.392191886901855 | Actual: 38.02 | Error: 24.627808113098148\n"
     ]
    }
   ],
   "source": [
    "# multi thread model\n",
    "print(\"Validation set multi thread model\")\n",
    "min_instance, max_instance, predictions = describe_val(model_mm, X_mm_test, y_mm_test, y_mm_scaler)\n",
    "y_scaled = inv_scaling(y_mm_test, y_mm_scaler)\n",
    "errors = np.abs(predictions - y_scaled)\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "print(f\"Mean prediction: {np.mean(predictions)} | Std actual: {np.std(predictions)}\")\n",
    "print(f\"Mean actual: {np.mean(y_scaled)} | Std actual: {np.std(y_scaled)}\")\n",
    "print(f\"Mean Error: {mean_error} | Std Error: {std_error}\")\n",
    "print(\"Min instance\")\n",
    "print(mm_test.iloc[min_instance[\"index\"]])\n",
    "print(f\"Min Prediction: {min_instance['prediction']} | Actual: {min_instance['actual']} | Error: {abs(min_instance['prediction'] - min_instance['actual'])}\")\n",
    "print(\"---\")\n",
    "print(\"Max instance\")\n",
    "print(mm_test.iloc[max_instance[\"index\"]])\n",
    "print(f\"Max Prediction: {max_instance['prediction']} | Actual: {max_instance['actual']} | Error: {abs(max_instance['prediction'] - max_instance['actual'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
